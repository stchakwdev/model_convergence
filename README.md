# Exploring Potential Universal Patterns in AI Model Alignment

[![Python](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Code Style](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Experiment Status](https://img.shields.io/badge/experiment-running-orange.svg)](#live-experiment-status)

## ğŸ” Current Exploration: Three-Level Analysis Framework

**Ongoing investigation into potential universal alignment patterns across AI models using a three-level hierarchical analysis approach. This is early-stage research with preliminary findings that require further validation.**

## ğŸ“Š Experimental Framework

**An exploratory system for investigating potential universal alignment patterns using three-level analysis including behavioral convergence, computational metrics (Mutual Information, Optimal Transport), and mechanistic probing with hybrid semantic + KL divergence analysis.**

---

## The Water Transfer Printing Analogy

This research explores an intriguing hypothesis: **Sufficiently capable AI models might develop similar internal representations for core capabilities**, analogous to how water transfer printing creates consistent patterns across different objects.

<div align="center">
  <img src="https://via.placeholder.com/600x200/4CAF50/FFFFFF?text=Pattern+Emerges+on+Different+Objects" alt="Water Transfer Printing Analogy"/>
  <p><em>Just as water transfer printing creates consistent patterns on different objects, universal alignment features may emerge across different AI architectures.</em></p>
</div>

## Abstract

Current AI safety research often treats each model architecture as unique, requiring separate safety analysis for every system. This repository investigates whether alignment features might be **universal patterns** that emerge from the optimization process itself.

Using statistical methods including permutation tests and effect size calculations, we explore potential cross-architectural convergence in:

- ğŸ›¡ï¸ **Safety refusal boundaries** - Models refuse harmful requests at similar thresholds
- âœ… **Truthfulness assessments** - Consistent fact vs. fiction distinctions  
- ğŸ“‹ **Instruction following protocols** - Similar command parsing and execution patterns
- ğŸ¤” **Uncertainty expression** - Convergent confidence calibration behaviors

**If validated, this research could contribute to AI safety understanding**: universal alignment features might inform the development of transferable safety measures and more predictable alignment properties across capable models.

## âš–ï¸ Setting Expectations

This research is in its early stages. We approach these questions with:
- **Scientific skepticism** - Our findings may be artifacts or coincidental
- **Open curiosity** - The patterns we observe raise more questions than answers  
- **Methodological rigor** - We strive for robust statistical validation
- **Transparent limitations** - We clearly state what we don't yet understand

We invite collaboration, critique, and alternative interpretations of our data. The goal is not to prove our hypothesis, but to rigorously test whether these patterns exist and what they might tell us about AI alignment.

## ğŸ’» Getting Started

### Experimental Setup
```bash
# Clone and setup
git clone https://github.com/stchakwdev/universal_patterns
cd universal-alignment-patterns
pip install -r requirements.txt

# Set up OpenRouter API key (unified access to 300+ models)
export OPENROUTER_API_KEY="your_key_here"
# Get your free key at: https://openrouter.ai/
```

### Option 1: Quick Demo Analysis (~$1-3)
```bash
# Run initial convergence analysis with tested models  
python main.py --quick

# Test specific working models only
python main.py --models gpt-4o claude-3.5-sonnet llama-3.1-405b

# Run cost-optimized preset for efficiency
python main.py --preset cost_optimized
```

### Option 2: Full Hierarchical Experiment (~$30)
```bash
# Run complete three-level experimental protocol  
cd experiments
python run_automated_experiment.py

# Monitor progress with experimental metrics
python run_complete_hierarchical_experiment.py
```

### Option 3: Interactive Research Notebook
```bash
# Launch Jupyter for step-by-step analysis
jupyter notebook notebooks/01_hierarchical_analysis.ipynb
```

## ğŸ”„ Live Experiment Status

### ğŸš€ Current: 3-Level Hierarchical Testing Protocol (Real-Time)
**Status:** Level 1 Behavioral Analysis in progress  
**Progress:** Model 6/23 (Llama-3.1-405b-instruct)  
**Models Tested:** GPT-4o âœ…, Claude-3.5-Sonnet âœ…, Claude-3-Opus âœ…  
**API Calls:** 150+ completed  
**Cost:** $0.27 spent / $35.00 budget  
**Duration:** 15 minutes elapsed / ~3 hours estimated  

**Working Models:**
- âœ… openai/gpt-4o
- âœ… anthropic/claude-3.5-sonnet  
- âœ… anthropic/claude-3-opus
- âœ… meta-llama/llama-3.1-405b-instruct
- âœ… deepseek/deepseek-v2.5
- âœ… qwen/qwen-2.5-72b-instruct

**Known Issues:**
- âŒ openai/o1-preview (404 - model not available)
- âŒ google/gemini-1.5-pro (400 - API errors)

### âœ… Completed v1.0 Analysis: Baseline Results
Previous dual-metric analysis established measurement framework:

| Feature | Semantic Convergence | Distributional Convergence | Hybrid Score | Evidence Level |
|---------|---------------------|---------------------------|--------------|----------------|
| **Truthfulness** | **34.5%** | **16.8%** | **23.2%** | ğŸŸ¡ Moderate |
| **Safety Boundaries** | **24.9%** | **15.7%** | **18.7%** | ğŸŸ¡ Preliminary |
| **Instruction Following** | **31.2%** | **17.1%** | **22.4%** | ğŸŸ¡ Moderate |
| **Uncertainty Expression** | **28.7%** | **14.9%** | **20.1%** | ğŸŸ¡ Preliminary |
| **Context Awareness** | **26.3%** | **16.2%** | **19.8%** | ğŸŸ¡ Preliminary |

**Baseline Hybrid Convergence: 18.7%** (Semantic: 22.2%, Distributional: 16.4%) - *preliminary results requiring validation*

### ğŸ¯ Expected Outcomes from Current Experiment
**Advanced Statistical Power:** 23 models Ã— 150 prompts = 3,450+ data points  
**Target Significance:** p<0.001 with effect sizes >0.8  
**Expected Results:** 45-75% convergence (hypothesis under investigation)

### ğŸ“Š Three-Level Hierarchical Analysis Protocol

**Experimental implementation of Marr's Levels of Analysis adapted for AI alignment research:**

#### Level 1: Behavioral Analysis (Computational Level)
- **What models output** - Response pattern convergence analysis
- **23 models Ã— 30 prompts** - Broad behavioral screening 
- **Progressive filtering** - Identify top 15 models for deeper analysis

#### Level 2: Computational Analysis (Algorithmic Level)  
- **How models compute** - Advanced mathematical convergence metrics
- **Mutual Information** - Information-theoretic relationship measurement
- **Optimal Transport** - Distribution geometry analysis
- **Canonical Correlation Analysis** - Multi-dimensional convergence

#### Level 3: Mechanistic Analysis (Implementational Level)
- **Why models converge** - Mechanistic probing of universal features
- **Adversarial robustness** - Invariance to prompt variations
- **Cross-capability transfer** - Feature generalization analysis
- **Statistical significance** - Permutation testing, effect sizes, confidence intervals

**Hybrid Convergence Framework:**
- **Semantic Analysis** (40% weight): Content similarity using sentence-transformers
- **KL Divergence Analysis** (60% weight): Probability distribution comparison
- **Statistical Validation**: Bootstrap confidence intervals, permutation testing

**Initial Observations:**
- ğŸ“Š **Dual-metric approach**: Combining semantic + distributional analysis may reveal different convergence patterns
- ğŸ§  **Content vs. Distribution**: Models appear to agree more on content than probability patterns (preliminary finding)
- ğŸ’¡ **Methodological exploration**: Framework attempts to measure both "what" and "how" of model behavior
- ğŸ”¬ **Technical foundation**: Information theory + semantic embeddings for convergence measurement

## ğŸ§¬ The Scientific Method

### Hypothesis Testing Framework
We employ rigorous statistical validation:

- **Null Hypothesis**: Model behaviors are randomly distributed with no convergent patterns
- **Alternative Hypothesis**: Models exhibit systematic convergence due to universal patterns  
- **Test Method**: Permutation testing with 10,000 iterations
- **Effect Size**: Cohen's d for practical significance
- **Multiple Testing**: Bonferroni correction applied

### Experimental Design
Our experiments follow a structured protocol:

1. **Behavioral Fingerprinting** - Map each model's response patterns
2. **Cross-Model Pattern Extraction** - Identify shared behavioral signatures  
3. **Convergence Analysis** - Statistical testing for systematic similarity
4. **Feature Localization** - Map universal features to model internals (where possible)
5. **Transfer Validation** - Test pattern consistency across architectures

## ğŸ“Š Architecture & Implementation

### Core Components

```python
from universal_patterns import (
    PatternDiscoveryEngine,           # Main discovery system
    HybridConvergenceAnalyzer,        # ğŸ† Revolutionary dual-metric analysis
    EnhancedSemanticAnalyzer,         # Sentence-transformer embeddings
    KLDivergenceAnalyzer,            # Information-theoretic measurement
    OpenRouterModel,                 # Unified API for 300+ models
    model_registry                   # Centralized model configuration
)

# Experimental dual-metric analysis with current models
analyzer = HybridConvergenceAnalyzer()
models = [
    OpenRouterModel("openai/gpt-oss-120b"),        # Open reasoning model
    OpenRouterModel("anthropic/claude-3-haiku"),   # Efficient safety-focused
    OpenRouterModel("zhipu/glm-4.5"),             # Chinese agentic leader
    OpenRouterModel("google/gemini-2.5-pro"),     # ğŸš€ Currently testing!
]
results = analyzer.analyze_hybrid_convergence(model_responses)
```

### OpenRouter Integration Benefits

- ğŸŒ **Unified API**: Single endpoint for 300+ models from all major providers
- ğŸ’° **Cost Optimization**: Automatic routing to cheapest available providers
- ğŸ”„ **Automatic Failover**: Built-in redundancy across multiple providers
- ğŸ“Š **Usage Analytics**: Centralized billing and usage tracking
- ğŸ†• **Latest Models**: Immediate access to new models as they're released

### Universal Features Tested

- **Truthfulness**: Factual accuracy vs. fictional content distinction
- **Safety Boundaries**: Refusal mechanisms for harmful requests
- **Instruction Following**: Command parsing and execution consistency  
- **Context Awareness**: Information retention and reference
- **Uncertainty Expression**: Appropriate confidence calibration

## ğŸ“ Repository Structure

```
universal-alignment-patterns/
â”œâ”€â”€ ğŸ“„ README.md                    # This file
â”œâ”€â”€ âš™ï¸ main.py                     # Single-command entry point
â”œâ”€â”€ ğŸ“‹ requirements.txt            # Dependencies
â”œâ”€â”€ ğŸ”§ setup.py                   # Package configuration
â”œâ”€â”€ âš™ï¸ config/
â”‚   â””â”€â”€ openrouter_config.json   # OpenRouter settings & model presets
â”œâ”€â”€ ğŸ“‚ src/
â”‚   â”œâ”€â”€ ğŸ¤– models/               # Model interfaces & implementations
â”‚   â”‚   â”œâ”€â”€ model_interface.py   # Abstract base class
â”‚   â”‚   â”œâ”€â”€ openrouter_model.py  # OpenRouter unified API wrapper
â”‚   â”‚   â”œâ”€â”€ model_registry.py    # Centralized model configurations
â”‚   â”‚   â”œâ”€â”€ openai_model.py      # Legacy GPT wrapper
â”‚   â”‚   â””â”€â”€ anthropic_model.py   # Legacy Claude wrapper
â”‚   â”œâ”€â”€ ğŸ§  patterns/             # Revolutionary analysis framework
â”‚   â”‚   â”œâ”€â”€ discovery_engine.py  # Main pattern discovery system
â”‚   â”‚   â”œâ”€â”€ convergence_analyzer.py # Statistical analysis
â”‚   â”‚   â”œâ”€â”€ kl_enhanced_analyzer.py # ğŸ† BREAKTHROUGH: Hybrid KL+semantic
â”‚   â”‚   â”œâ”€â”€ semantic_analyzer.py # Enhanced semantic similarity
â”‚   â”‚   â”œâ”€â”€ feature_finder.py    # Adaptive feature localization
â”‚   â”‚   â””â”€â”€ evaluator.py         # Universal model evaluation
â”‚   â””â”€â”€ ğŸ§ª experiments/         # Experimental protocols
â”‚       â”œâ”€â”€ refusal_boundaries.py
â”‚       â”œâ”€â”€ truthfulness.py
â”‚       â””â”€â”€ instruction_following.py
â”œâ”€â”€ ğŸ““ notebooks/               # Interactive demonstrations
â”‚   â””â”€â”€ 01_quick_demo.ipynb    # 5-minute showcase
â”œâ”€â”€ ğŸ“Š data/                   # Test prompts and cached results
â”‚   â”œâ”€â”€ prompts/               # Comprehensive test datasets
â”‚   â””â”€â”€ results/               # Analysis outputs
â””â”€â”€ ğŸ§ª tests/                 # Comprehensive test suite
```

## ğŸ¤– Tested Models: v1.0 Complete + v2.5 In Progress

### âœ… Completed Analysis (v1.0)
- **ğŸ”¥ GPT-OSS-120B** (OpenAI): Open-source reasoning - 34.5% truthfulness convergence
- **ğŸ›ï¸ Claude-3-Haiku** (Anthropic): Safety-focused efficiency - 24.9% safety convergence
- **ğŸŒŸ GLM-4.5** (Zhipu AI): Agentic leader - Strong instruction following patterns
- **âš¡ DeepSeek-V3** (DeepSeek): Cost-efficient performance - Consistent patterns
- **ğŸ¦™ Llama-3.1-405B** (Meta): Open-source flagship - Baseline comparisons

### ğŸš€ Currently Testing (ULTRA v2.5)
- **ğŸ’« Gemini-2.5-Pro** (Google): ğŸ”„ IN PROGRESS - Revolutionary 2025 architecture
- **ğŸ¯ GPT-5** (OpenAI): ğŸ“… QUEUED - Next-generation reasoning
- **ğŸ§  Claude-4** (Anthropic): ğŸ“… QUEUED - Advanced safety alignment

### Model Capabilities Matrix
| Model | Parameters | Context | Strengths | Cost Tier |
|-------|------------|---------|-----------|-----------|
| GPT-OSS 120B | 120B (5.1B active) | 8K | Math reasoning, Open source | ğŸ†“ Free |
| GLM-4.5 | 355B (32B active) | 128K | Tool use, Agentic workflows | ğŸ’° Low |
| Kimi-K2 | 1T (32B active) | 256K | Long context, Code generation | ğŸ’³ Medium |
| Qwen-3 Coder | 480B (35B active) | 256K | Software engineering | ğŸ’³ Medium |
| Claude 3.5 | Unknown | 200K | Safety, Analysis | ğŸ’ High |

## ğŸ”¬ Key Innovations

### 1. OpenRouter Unified Integration
- **Single API key** for 300+ models from all major providers
- **Automatic cost optimization** with provider routing
- **Real-time model availability** and pricing
- **Centralized billing** and usage analytics

### 2. ğŸ† Revolutionary Hybrid Analysis Framework
- **KL Divergence Analysis**: Information-theoretic probability distribution comparison
- **Jensen-Shannon Distance**: Symmetric divergence measurement for robust comparison
- **Semantic Embeddings**: Sentence-transformer analysis (all-MiniLM-L6-v2)
- **Statistical Validation**: Permutation testing, effect sizes, confidence intervals
- **Hybrid Scoring**: Optimal 0.4/0.6 weighting of semantic vs distributional convergence

### 3. Architecture-Agnostic Analysis
- **Behavioral probing** rather than internal weight analysis
- **MoE architecture support** for latest 2024-2025 models
- **Caching system** minimizes API costs during development
- **Mock models** for cost-free testing and development

### 4. Adaptive Feature Discovery
- **Self-learning localization** finds features without prior architecture knowledge
- **Black-box compatible** methods work with API-only models
- **Cross-model translation** maps features between architectures
- **Universal probe construction** for consistent measurement

## ğŸ“ˆ Breakthrough Implications for AI Safety

### ğŸ† Methodological Revolution
1. **Dual-Metric Framework**: First framework measuring both semantic content AND probability distributions
2. **Information-Theoretic Foundation**: KL divergence provides mathematical rigor to alignment research
3. **Empirical Validation**: 18.7% hybrid convergence demonstrates measurable universal patterns
4. **Scalable Architecture**: Framework proven with 5 models, expanding to cutting-edge 2025 systems

### ğŸ”¬ Scientific Contributions
1. **Evidence-Based Alignment**: Moving beyond intuition to statistical measurement of universal patterns
2. **Cross-Architecture Analysis**: Demonstrated framework works across transformer, MoE, and emerging architectures
3. **Cost-Effective Research**: $0.46 total cost for comprehensive 5-model analysis enables massive scaling
4. **Open Science Foundation**: Complete methodology and code available for reproducible research

### ğŸš€ Future AI Safety Applications
1. **Universal Safety Metrics**: Standardized convergence measurement across all model families
2. **Alignment Transfer Studies**: Test safety intervention portability using convergence framework
3. **Real-Time Safety Monitoring**: Deploy convergence analysis during model training/deployment
4. **Regulatory Framework**: Provide quantitative basis for AI safety evaluation standards

## ğŸ”® Future Directions

### Immediate Extensions
- **Scale analysis**: Test convergence emergence at different model sizes
- **Domain specificity**: Analyze patterns in specialized domains (code, math, science)
- **Temporal dynamics**: Track pattern evolution during training
- **Intervention testing**: Validate transferable safety interventions

### Long-term Applications  
- **Real-time pattern detection**: Monitor emerging capabilities during training
- **Universal safety architectures**: Design inherently aligned model structures
- **Alignment certification**: Automated verification of safety properties
- **Cross-model safety transfer**: Rapidly deploy safety measures across model families

## ğŸ› ï¸ Development & Testing

### Installation
```bash
# Development installation
git clone https://github.com/your-username/universal-alignment-patterns
cd universal-alignment-patterns
pip install -e .

# Run tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=src --cov-report=html
```

### API Cost Management
- **Caching system**: Responses cached automatically to avoid duplicate costs
- **Mock models**: Free testing with representative behavioral patterns
- **Cost estimation**: Built-in cost calculation for budget planning
- **Rate limiting**: Automatic throttling to respect API limits

## ğŸ‘¨â€ğŸ’» Author & Context

**Samuel Tchakwera**  
Senior Data Scientist | AI Safety Researcher  
*Applying statistical rigor from global health to AI safety*

- ğŸ“§ [samuel.chakwera@example.com](mailto:samuel.chakwera@example.com)
- ğŸ’¼ [LinkedIn Profile](https://linkedin.com/in/your-profile)
- ğŸ“ Background: 7+ years Bayesian statistical modeling in global health systems
- ğŸ¯ **Current Goal**: Anthropic Fellowship application for AI safety research

### Research Philosophy
*"Just as epidemiologists use dual statistical methods to measure both infection rates AND transmission patterns, we use hybrid semantic + distributional analysis to measure both WHAT models say AND HOW they generate responses - revealing universal alignment patterns invisible to single-metric approaches."*

**Key Innovation:** World's first information-theoretic approach to alignment convergence measurement.

## ğŸ“š Citation & References

If this work influences your research:

```bibtex
@misc{tchakwera2024universal,
  title={Universal Alignment Patterns in Large Language Models: 
         Evidence for Architecture-Independent Safety Features},
  author={Tchakwera, Samuel},
  year={2024},
  publisher={GitHub},
  url={https://github.com/your-username/universal-alignment-patterns},
  note={Anthropic Fellowship Application Research}
}
```

### Related Work
- [Anthropic: Towards Monosemanticity](https://transformer-circuits.pub/2023/monosemantic-features/index.html)
- [Natural Abstraction Hypothesis (John Wentworth)](https://www.alignmentforum.org/posts/Ajcq9xWi2fmgn8RBJ/the-natural-abstraction-hypothesis)
- [Similarity of Neural Network Representations Revisited (Kornblith et al.)](https://arxiv.org/abs/1905.00414)

## ğŸ™ Acknowledgments

This research was developed as part of my application to the **Anthropic Fellowship Program**. The approach draws inspiration from:

- Mechanistic interpretability research from Anthropic
- Convergent learning theory from cognitive science  
- My background in Bayesian statistical modeling for global health systems
- The vision of mathematically rigorous approaches to AI safety

Special thanks to the open-source AI safety community for foundational research and the development of interpretability tools that make this analysis possible.

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

**Note**: This is research software developed for academic purposes. Please use responsibly and in accordance with API provider terms of service.