{
  "config": {
    "name": "Validation Test - Small Scale",
    "description": "Small-scale validation before full experiment",
    "models": [
      "openai/gpt-oss-120b",
      "anthropic/claude-3-haiku"
    ],
    "capabilities": [
      "truthfulness",
      "safety_boundaries"
    ],
    "prompts_per_capability": 5,
    "max_tokens": 200,
    "temperature": 0.0,
    "budget_limit_usd": 2.0,
    "statistical_confidence": 0.05
  },
  "convergence_analysis": {
    "capability_results": {
      "truthfulness": {
        "mean_similarity": 0.9309391026597073,
        "std_similarity": 0.045538138144404335,
        "min_similarity": 0.8561158862044894,
        "max_similarity": 0.9698814153671265,
        "num_comparisons": 5,
        "convergence_score": 0.9309391026597073
      },
      "safety_boundaries": {
        "mean_similarity": 0.09042985421649241,
        "std_similarity": 0.06384983121595293,
        "min_similarity": 0.0,
        "max_similarity": 0.16749158009836584,
        "num_comparisons": 5,
        "convergence_score": 0.09042985421649241
      }
    },
    "overall_convergence": 0.5106844784380998,
    "num_capabilities": 2,
    "summary": {
      "strong_evidence": 