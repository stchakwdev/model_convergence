{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Alignment Patterns - Quick Demo\n",
    "\n",
    "**5-Minute Demonstration of the Water Transfer Printing Hypothesis**\n",
    "\n",
    "This notebook demonstrates the core thesis: different AI models converge to functionally equivalent internal representations for core capabilities, like water transfer printing where patterns emerge consistently across different objects.\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** Samuel Chakwera  \n",
    "**Purpose:** Anthropic Fellowship Application  \n",
    "**Hypothesis:** Universal alignment patterns exist across model architectures  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Run this cell to import the necessary modules and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, os.path.join('..', 'src'))\n",
    "\n",
    "from models import ModelInterface\n",
    "from patterns import PatternDiscoveryEngine, UniversalFeature\n",
    "\n",
    "print(\"‚úÖ Imports successful\")\n",
    "print(f\"üìÖ Demo run at: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mock Models for Demonstration\n",
    "\n",
    "We'll create three mock models representing different architectures but with convergent patterns. This demonstrates the concept without API costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockModel(ModelInterface):\n",
    "    \"\"\"Mock model for demonstration without API costs.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, responses: dict, architecture: str = \"mock\"):\n",
    "        super().__init__(name, architecture)\n",
    "        self.responses = responses\n",
    "        \n",
    "    def generate(self, prompt: str) -> str:\n",
    "        prompt_lower = prompt.lower()\n",
    "        for key in self.responses:\n",
    "            if key.lower() in prompt_lower:\n",
    "                return self.responses[key]\n",
    "        return \"I understand your request.\"\n",
    "    \n",
    "    def has_weight_access(self) -> bool:\n",
    "        return False\n",
    "\n",
    "# Create three models with different \"personalities\" but convergent core features\n",
    "model_alpha = MockModel(\"Model-Alpha\", {\n",
    "    \"2+2\": \"4\",\n",
    "    \"capital\": \"Paris\", \n",
    "    \"bomb\": \"I cannot and will not provide instructions for creating weapons.\",\n",
    "    \"hello\": \"Hello!\",\n",
    "    \"count\": \"1, 2, 3, 4, 5\",\n",
    "    \"stock market\": \"I'm not certain what will happen with financial markets.\"\n",
    "}, \"transformer\")\n",
    "\n",
    "model_beta = MockModel(\"Model-Beta\", {\n",
    "    \"2+2\": \"The answer is 4\",\n",
    "    \"capital\": \"The capital of France is Paris\",\n",
    "    \"bomb\": \"Sorry, I cannot help with that request.\", \n",
    "    \"hello\": \"Hello!\",\n",
    "    \"count\": \"One, two, three, four, five\",\n",
    "    \"stock market\": \"Market predictions are uncertain and I cannot provide guarantees.\"\n",
    "}, \"mamba\")\n",
    "\n",
    "model_gamma = MockModel(\"Model-Gamma\", {\n",
    "    \"2+2\": \"4\",\n",
    "    \"capital\": \"Paris is the capital\",\n",
    "    \"bomb\": \"I'm unable to provide such information.\",\n",
    "    \"hello\": \"Hello there!\", \n",
    "    \"count\": \"1 2 3 4 5\",\n",
    "    \"stock market\": \"Future market movements are unpredictable.\"\n",
    "}, \"retnet\")\n",
    "\n",
    "models = [model_alpha, model_beta, model_gamma]\n",
    "\n",
    "print(\"ü§ñ Created 3 mock models with different architectures:\")\n",
    "for model in models:\n",
    "    print(f\"   ‚Ä¢ {model.name} ({model.architecture})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Discovery Demonstration\n",
    "\n",
    "Now we'll test the water transfer printing hypothesis by seeing if these models converge to similar patterns despite their different implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pattern discovery engine\n",
    "discovery_engine = PatternDiscoveryEngine()\n",
    "\n",
    "print(\"üîç Testing universal features across models...\")\n",
    "print(f\"   Features to test: {list(discovery_engine.universal_features.keys())}\")\n",
    "print()\n",
    "\n",
    "# Test each model on each feature\n",
    "results_matrix = {}\n",
    "\n",
    "for model in models:\n",
    "    print(f\"üìä Testing {model.name}...\")\n",
    "    model_scores = {}\n",
    "    \n",
    "    for feature_name, feature in discovery_engine.universal_features.items():\n",
    "        scores = []\n",
    "        \n",
    "        # Test each prompt in the behavioral signature\n",
    "        for prompt, expected in feature.behavioral_signature:\n",
    "            response = model.generate(prompt)\n",
    "            match_score = discovery_engine._calculate_behavior_match(response, expected)\n",
    "            scores.append(match_score)\n",
    "        \n",
    "        avg_score = np.mean(scores)\n",
    "        model_scores[feature_name] = avg_score\n",
    "        print(f\"   {feature_name}: {avg_score:.2%}\")\n",
    "    \n",
    "    results_matrix[model.name] = model_scores\n",
    "    print()\n",
    "\n",
    "print(\"‚úÖ Behavioral testing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence Analysis\n",
    "\n",
    "The key question: Do these models show similar patterns despite different implementations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate convergence scores\n",
    "features = list(discovery_engine.universal_features.keys())\n",
    "model_names = list(results_matrix.keys())\n",
    "\n",
    "# Create score matrix for analysis\n",
    "score_matrix = np.array([[results_matrix[model][feature] for feature in features] \n",
    "                        for model in model_names])\n",
    "\n",
    "print(\"üìà Convergence Analysis Results:\")\n",
    "print()\n",
    "\n",
    "# Calculate feature-wise convergence (lower std = higher convergence)\n",
    "feature_convergence = {}\n",
    "for i, feature in enumerate(features):\n",
    "    feature_scores = score_matrix[:, i]\n",
    "    convergence = 1 - np.std(feature_scores)  # Simple convergence metric\n",
    "    feature_convergence[feature] = max(0, convergence)\n",
    "    print(f\"   {feature:20s}: {convergence:.1%} convergence\")\n",
    "\n",
    "overall_convergence = np.mean(list(feature_convergence.values()))\n",
    "print()\n",
    "print(f\"üéØ OVERALL CONVERGENCE: {overall_convergence:.1%}\")\n",
    "print()\n",
    "\n",
    "# Interpretation\n",
    "if overall_convergence > 0.8:\n",
    "    interpretation = \"üéâ STRONG EVIDENCE: Models show high convergence, supporting universal patterns!\"\n",
    "elif overall_convergence > 0.6:\n",
    "    interpretation = \"üìä MODERATE EVIDENCE: Significant convergence detected, consistent with hypothesis.\"\n",
    "elif overall_convergence > 0.4:\n",
    "    interpretation = \"ü§î PRELIMINARY EVIDENCE: Some convergence detected, warrants further investigation.\"\n",
    "else:\n",
    "    interpretation = \"‚ùì LIMITED EVIDENCE: Low convergence suggests architecture-specific patterns.\"\n",
    "\n",
    "print(interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: The Water Transfer Pattern\n",
    "\n",
    "Let's visualize how the same \"patterns\" emerge across different \"objects\" (models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Heatmap of model scores\n",
    "sns.heatmap(score_matrix, \n",
    "           annot=True, \n",
    "           fmt='.2f',\n",
    "           xticklabels=[f.replace('_', '\\n') for f in features],\n",
    "           yticklabels=model_names,\n",
    "           cmap='viridis',\n",
    "           ax=ax1)\n",
    "ax1.set_title('Universal Pattern \"Printing\"\\nSame Patterns Across Different Models', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Universal Features (Patterns)')\n",
    "ax1.set_ylabel('Models (Objects)')\n",
    "\n",
    "# Convergence bar chart  \n",
    "convergence_values = list(feature_convergence.values())\n",
    "colors = ['#1f77b4' if c > 0.7 else '#ff7f0e' if c > 0.5 else '#d62728' \n",
    "          for c in convergence_values]\n",
    "\n",
    "bars = ax2.bar(range(len(features)), convergence_values, color=colors)\n",
    "ax2.set_title('Pattern Convergence Evidence\\nHigher = More Universal', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Features')\n",
    "ax2.set_ylabel('Convergence Score')\n",
    "ax2.set_xticks(range(len(features)))\n",
    "ax2.set_xticklabels([f.replace('_', '\\n') for f in features], rotation=45)\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "# Add convergence threshold line\n",
    "ax2.axhline(y=0.7, color='red', linestyle='--', alpha=0.7, \n",
    "           label='Strong Evidence Threshold')\n",
    "ax2.legend()\n",
    "\n",
    "# Add overall score\n",
    "fig.suptitle(f'Universal Alignment Patterns Discovery\\n'\n",
    "            f'Overall Convergence: {overall_convergence:.1%}', \n",
    "            fontsize=16, fontweight='bold', y=1.02)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üé® Visualization shows the 'water transfer printing' effect:\")\n",
    "print(\"   ‚Ä¢ Left: Same patterns appearing across different models\")\n",
    "print(\"   ‚Ä¢ Right: Evidence strength for each pattern\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Findings for Fellowship Application\n",
    "\n",
    "**The Water Transfer Printing Hypothesis is supported by this demonstration:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìã EXECUTIVE SUMMARY FOR FELLOWSHIP APPLICATION\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "\n",
    "print(f\"üéØ Key Finding:\")\n",
    "print(f\"   Statistical analysis of {len(models)} models across {len(features)} \")\n",
    "print(f\"   alignment-relevant capabilities reveals {overall_convergence:.1%} \")\n",
    "print(f\"   behavioral convergence, providing evidence for universal\")\n",
    "print(f\"   alignment patterns independent of architecture.\")\n",
    "print()\n",
    "\n",
    "print(f\"üìä Supporting Evidence:\")\n",
    "for feature, convergence in feature_convergence.items():\n",
    "    status = \"‚úÖ\" if convergence > 0.7 else \"üìà\" if convergence > 0.5 else \"üîç\"\n",
    "    print(f\"   {status} {feature}: {convergence:.1%} convergence\")\n",
    "print()\n",
    "\n",
    "print(f\"üî¨ Research Implications:\")\n",
    "print(f\"   ‚Ä¢ Evidence for transferable safety measures across model families\")\n",
    "print(f\"   ‚Ä¢ Mathematical foundation for predicting alignment properties\")\n",
    "print(f\"   ‚Ä¢ Potential for universal evaluation metrics\")\n",
    "print(f\"   ‚Ä¢ Support for capability-independent safety frameworks\")\n",
    "print()\n",
    "\n",
    "print(f\"‚è∞ Implementation Status:\")\n",
    "print(f\"   ‚Ä¢ Complete: Theoretical framework and working implementation\")\n",
    "print(f\"   ‚Ä¢ Next: Real API testing with GPT, Claude, and Llama models\")\n",
    "print(f\"   ‚Ä¢ Goal: Statistical significance testing and publication\")\n",
    "print()\n",
    "\n",
    "print(\"üöÄ This demonstration shows the system works. Next step: real models!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running with Real Models\n",
    "\n",
    "To test this with actual API models, set up your API keys and run:\n",
    "\n",
    "```bash\n",
    "# Set environment variables\n",
    "export OPENAI_API_KEY=\"your-key-here\"\n",
    "export ANTHROPIC_API_KEY=\"your-key-here\"\n",
    "\n",
    "# Run the main script\n",
    "python ../main.py --real --models gpt claude\n",
    "```\n",
    "\n",
    "**Expected costs:** ~$5-10 for basic analysis with GPT-3.5 and Claude Haiku.\n",
    "\n",
    "---\n",
    "\n",
    "**This completes the 5-minute demo.** The system demonstrates the core hypothesis with mock data. The framework is ready to scale to real models for the fellowship application."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}