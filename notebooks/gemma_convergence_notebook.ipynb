{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemma Model Convergence Experiment\n",
    "## Multi-Model SAE-Enhanced Pattern Discovery\n",
    "\n",
    "This notebook implements a comprehensive experiment to analyze convergence patterns across different Gemma model variants using Sparse Autoencoders (SAEs) and mechanistic interpretability techniques.\n",
    "\n",
    "**Key Innovation**: We combine behavioral convergence analysis with SAE feature analysis to detect universal patterns at both behavioral and mechanistic levels.\n",
    "\n",
    "### Experiment Overview:\n",
    "- **Models**: Gemma 2B/9B (base & instruct variants)\n",
    "- **Analysis Levels**: Behavioral, Activation, SAE Feature\n",
    "- **Framework**: TransformerLens + Gemma Scope SAEs + Universal Patterns\n",
    "\n",
    "### Requirements:\n",
    "- GPU with 16GB+ VRAM (recommended for runpod)\n",
    "- HuggingFace account with Gemma access\n",
    "- Python 3.8+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ Runpod Setup Instructions\n",
    "\n",
    "### 1. Launch Runpod Instance\n",
    "```bash\n",
    "# Recommended template: PyTorch 2.0+ with CUDA\n",
    "# GPU: RTX 4090 or A100 (24GB VRAM recommended)\n",
    "# Storage: 50GB+ for models and results\n",
    "```\n",
    "\n",
    "### 2. SSH Connection\n",
    "```bash\n",
    "# Connect via SSH\n",
    "ssh root@<pod-ip> -p <ssh-port>\n",
    "\n",
    "# Or use runpod CLI\n",
    "runpod ssh <pod-id>\n",
    "```\n",
    "\n",
    "### 3. Environment Setup\n",
    "Run the setup cell below to install all dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Installing required packages...\n",
      "Installing transformer-lens...\n",
      "Collecting transformer-lens\n",
      "  Downloading transformer_lens-2.16.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting accelerate>=0.23.0 (from transformer-lens)\n",
      "  Downloading accelerate-1.10.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting beartype<0.15.0,>=0.14.1 (from transformer-lens)\n",
      "  Downloading beartype-0.14.1-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting better-abc<0.0.4,>=0.0.3 (from transformer-lens)\n",
      "  Downloading better_abc-0.0.3-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting datasets>=2.7.1 (from transformer-lens)\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting einops>=0.6.0 (from transformer-lens)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting fancy-einsum>=0.0.3 (from transformer-lens)\n",
      "  Downloading fancy_einsum-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jaxtyping>=0.2.11 (from transformer-lens)\n",
      "  Downloading jaxtyping-0.3.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting numpy<2,>=1.24 (from transformer-lens)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB)\n",
      "Collecting pandas>=1.1.5 (from transformer-lens)\n",
      "  Downloading pandas-2.3.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Collecting rich>=12.6.0 (from transformer-lens)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting sentencepiece (from transformer-lens)\n",
      "  Downloading sentencepiece-0.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Collecting torch>=2.6 (from transformer-lens)\n",
      "  Downloading torch-2.8.0-cp311-none-macosx_11_0_arm64.whl.metadata (30 kB)\n",
      "Collecting tqdm>=4.64.1 (from transformer-lens)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting transformers>=4.51 (from transformer-lens)\n",
      "  Using cached transformers-4.55.2-py3-none-any.whl.metadata (41 kB)\n",
      "Collecting transformers-stream-generator<0.0.6,>=0.0.5 (from transformer-lens)\n",
      "  Downloading transformers-stream-generator-0.0.5.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting typeguard<5.0,>=4.2 (from transformer-lens)\n",
      "  Downloading typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting typing-extensions (from transformer-lens)\n",
      "  Using cached typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting wandb>=0.13.5 (from transformer-lens)\n",
      "  Downloading wandb-0.21.1-py3-none-macosx_11_0_arm64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from accelerate>=0.23.0->transformer-lens) (25.0)\n",
      "Requirement already satisfied: psutil in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from accelerate>=0.23.0->transformer-lens) (5.9.5)\n",
      "Collecting pyyaml (from accelerate>=0.23.0->transformer-lens)\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting huggingface_hub>=0.21.0 (from accelerate>=0.23.0->transformer-lens)\n",
      "  Using cached huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting safetensors>=0.4.3 (from accelerate>=0.23.0->transformer-lens)\n",
      "  Using cached safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting filelock (from datasets>=2.7.1->transformer-lens)\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets>=2.7.1->transformer-lens)\n",
      "  Downloading pyarrow-21.0.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.7.1->transformer-lens)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting requests>=2.32.2 (from datasets>=2.7.1->transformer-lens)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting xxhash (from datasets>=2.7.1->transformer-lens)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets>=2.7.1->transformer-lens)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer-lens)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting wadler-lindig>=0.1.3 (from jaxtyping>=0.2.11->transformer-lens)\n",
      "  Downloading wadler_lindig-0.1.7-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from pandas>=1.1.5->transformer-lens) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.1.5->transformer-lens)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.1.5->transformer-lens)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=12.6.0->transformer-lens)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from rich>=12.6.0->transformer-lens) (2.19.2)\n",
      "Collecting sympy>=1.13.3 (from torch>=2.6->transformer-lens)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=2.6->transformer-lens)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=2.6->transformer-lens)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.51->transformer-lens)\n",
      "  Downloading regex-2025.7.34-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers>=4.51->transformer-lens)\n",
      "  Using cached tokenizers-0.21.4-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting click!=8.0.0,>=7.1 (from wandb>=0.13.5->transformer-lens)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb>=0.13.5->transformer-lens)\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from wandb>=0.13.5->transformer-lens) (3.9.1)\n",
      "Collecting protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 (from wandb>=0.13.5->transformer-lens)\n",
      "  Downloading protobuf-6.32.0-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Collecting pydantic<3 (from wandb>=0.13.5->transformer-lens)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb>=0.13.5->transformer-lens)\n",
      "  Downloading sentry_sdk-2.35.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer-lens)\n",
      "  Downloading aiohttp-3.12.15-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface_hub>=0.21.0->accelerate>=0.23.0->transformer-lens)\n",
      "  Downloading hf_xet-1.1.8-cp37-abi3-macosx_11_0_arm64.whl.metadata (703 bytes)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer-lens)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3->wandb>=0.13.5->transformer-lens)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3->wandb>=0.13.5->transformer-lens)\n",
      "  Downloading pydantic_core-2.33.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3->wandb>=0.13.5->transformer-lens)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->transformer-lens) (1.16.0)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.32.2->datasets>=2.7.1->transformer-lens)\n",
      "  Downloading charset_normalizer-3.4.3-cp311-cp311-macosx_10_9_universal2.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.32.2->datasets>=2.7.1->transformer-lens)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.32.2->datasets>=2.7.1->transformer-lens)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.32.2->datasets>=2.7.1->transformer-lens)\n",
      "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.6->transformer-lens)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2.6->transformer-lens)\n",
      "  Downloading MarkupSafe-3.0.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer-lens)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer-lens)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer-lens)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer-lens)\n",
      "  Downloading frozenlist-1.7.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer-lens)\n",
      "  Downloading multidict-6.6.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer-lens)\n",
      "  Downloading propcache-0.3.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.7.1->transformer-lens)\n",
      "  Downloading yarl-1.20.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (73 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading transformer_lens-2.16.1-py3-none-any.whl (192 kB)\n",
      "Downloading accelerate-1.10.0-py3-none-any.whl (374 kB)\n",
      "Downloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading better_abc-0.0.3-py3-none-any.whl (3.5 kB)\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
      "Downloading jaxtyping-0.3.2-py3-none-any.whl (55 kB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Downloading pandas-2.3.1-cp311-cp311-macosx_11_0_arm64.whl (10.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Downloading torch-2.8.0-cp311-none-macosx_11_0_arm64.whl (73.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m73.6/73.6 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached transformers-4.55.2-py3-none-any.whl (11.3 MB)\n",
      "Downloading typeguard-4.4.4-py3-none-any.whl (34 kB)\n",
      "Using cached typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Downloading wandb-0.21.1-py3-none-macosx_11_0_arm64.whl (21.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.2/21.2 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.1-cp311-cp311-macosx_11_0_arm64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Using cached huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Downloading protobuf-6.32.0-cp39-abi3-macosx_10_9_universal2.whl (426 kB)\n",
      "Downloading pyarrow-21.0.0-cp311-cp311-macosx_12_0_arm64.whl (31.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.2/31.2 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp311-cp311-macosx_11_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl (172 kB)\n",
      "Downloading regex-2025.7.34-cp311-cp311-macosx_11_0_arm64.whl (285 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached safetensors-0.6.2-cp38-abi3-macosx_11_0_arm64.whl (432 kB)\n",
      "Downloading sentry_sdk-2.35.0-py2.py3-none-any.whl (363 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached tokenizers-0.21.4-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Downloading wadler_lindig-0.1.7-py3-none-any.whl (20 kB)\n",
      "Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading aiohttp-3.12.15-cp311-cp311-macosx_11_0_arm64.whl (471 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Downloading charset_normalizer-3.4.3-cp311-cp311-macosx_10_9_universal2.whl (204 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading hf_xet-1.1.8-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp311-cp311-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.7.0-cp311-cp311-macosx_11_0_arm64.whl (47 kB)\n",
      "Downloading multidict-6.6.4-cp311-cp311-macosx_11_0_arm64.whl (44 kB)\n",
      "Downloading propcache-0.3.2-cp311-cp311-macosx_11_0_arm64.whl (43 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading yarl-1.20.1-cp311-cp311-macosx_11_0_arm64.whl (89 kB)\n",
      "Building wheels for collected packages: transformers-stream-generator\n",
      "  Building wheel for transformers-stream-generator (setup.py): started\n",
      "  Building wheel for transformers-stream-generator (setup.py): finished with status 'done'\n",
      "  Created wheel for transformers-stream-generator: filename=transformers_stream_generator-0.0.5-py3-none-any.whl size=12425 sha256=6f1aac4344671c67c9cfd1f4b5e57c46fea1bdb627cb11e94a4262547482c42b\n",
      "  Stored in directory: /Users/samueltchakwera/Library/Caches/pip/wheels/23/e8/f0/b3c58c12d1ffe60bcc8c7d121115f26b2c1878653edfca48db\n",
      "Successfully built transformers-stream-generator\n",
      "Installing collected packages: pytz, mpmath, better-abc, xxhash, wadler-lindig, urllib3, tzdata, typing-extensions, tqdm, sympy, smmap, sentencepiece, safetensors, regex, pyyaml, pyarrow, protobuf, propcache, numpy, networkx, multidict, mdurl, MarkupSafe, idna, hf-xet, fsspec, frozenlist, filelock, fancy-einsum, einops, dill, click, charset_normalizer, certifi, beartype, attrs, annotated-types, aiohappyeyeballs, yarl, typing-inspection, typeguard, sentry-sdk, requests, pydantic-core, pandas, multiprocess, markdown-it-py, jinja2, jaxtyping, gitdb, aiosignal, torch, rich, pydantic, huggingface_hub, gitpython, aiohttp, wandb, tokenizers, accelerate, transformers, datasets, transformers-stream-generator, transformer-lens\n",
      "Successfully installed MarkupSafe-3.0.2 accelerate-1.10.0 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 annotated-types-0.7.0 attrs-25.3.0 beartype-0.14.1 better-abc-0.0.3 certifi-2025.8.3 charset_normalizer-3.4.3 click-8.2.1 datasets-4.0.0 dill-0.3.8 einops-0.8.1 fancy-einsum-0.0.3 filelock-3.19.1 frozenlist-1.7.0 fsspec-2025.3.0 gitdb-4.0.12 gitpython-3.1.45 hf-xet-1.1.8 huggingface_hub-0.34.4 idna-3.10 jaxtyping-0.3.2 jinja2-3.1.6 markdown-it-py-4.0.0 mdurl-0.1.2 mpmath-1.3.0 multidict-6.6.4 multiprocess-0.70.16 networkx-3.5 numpy-1.26.4 pandas-2.3.1 propcache-0.3.2 protobuf-6.32.0 pyarrow-21.0.0 pydantic-2.11.7 pydantic-core-2.33.2 pytz-2025.2 pyyaml-6.0.2 regex-2025.7.34 requests-2.32.5 rich-14.1.0 safetensors-0.6.2 sentencepiece-0.2.1 sentry-sdk-2.35.0 smmap-5.0.2 sympy-1.14.0 tokenizers-0.21.4 torch-2.8.0 tqdm-4.67.1 transformer-lens-2.16.1 transformers-4.55.2 transformers-stream-generator-0.0.5 typeguard-4.4.4 typing-extensions-4.14.1 typing-inspection-0.4.1 tzdata-2025.2 urllib3-2.5.0 wadler-lindig-0.1.7 wandb-0.21.1 xxhash-3.5.0 yarl-1.20.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing transformers>=4.30.0...\n",
      "Requirement already satisfied: transformers>=4.30.0 in /opt/homebrew/lib/python3.11/site-packages (4.55.2)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from transformers>=4.30.0) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/homebrew/lib/python3.11/site-packages (from transformers>=4.30.0) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/lib/python3.11/site-packages (from transformers>=4.30.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from transformers>=4.30.0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.11/site-packages (from transformers>=4.30.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/lib/python3.11/site-packages (from transformers>=4.30.0) (2025.7.34)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.11/site-packages (from transformers>=4.30.0) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/homebrew/lib/python3.11/site-packages (from transformers>=4.30.0) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/homebrew/lib/python3.11/site-packages (from transformers>=4.30.0) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/homebrew/lib/python3.11/site-packages (from transformers>=4.30.0) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.30.0) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.30.0) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.30.0) (1.1.8)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests->transformers>=4.30.0) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests->transformers>=4.30.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests->transformers>=4.30.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests->transformers>=4.30.0) (2025.8.3)\n",
      "Installing torch>=2.0.0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from torch>=2.0.0) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/homebrew/lib/python3.11/site-packages (from torch>=2.0.0) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/homebrew/lib/python3.11/site-packages (from torch>=2.0.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.11/site-packages (from torch>=2.0.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.11/site-packages (from torch>=2.0.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/lib/python3.11/site-packages (from torch>=2.0.0) (2025.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.0.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2->torch>=2.0.0) (3.0.2)\n",
      "Installing numpy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.11/site-packages (1.26.4)\n",
      "Installing scipy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.16.1-cp311-cp311-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: numpy<2.6,>=1.25.2 in /opt/homebrew/lib/python3.11/site-packages (from scipy) (1.26.4)\n",
      "Downloading scipy-1.16.1-cp311-cp311-macosx_14_0_arm64.whl (20.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scipy\n",
      "Successfully installed scipy-1.16.1\n",
      "Installing scikit-learn...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.1-cp311-cp311-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn) (1.16.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.1-cp311-cp311-macosx_12_0_arm64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.1 scikit-learn-1.7.1 threadpoolctl-3.6.0\n",
      "Installing matplotlib...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.59.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (108 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.3.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.10.5-cp311-cp311-macosx_11_0_arm64.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.3-cp311-cp311-macosx_11_0_arm64.whl (270 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.59.1-cp311-cp311-macosx_10_9_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.9-cp311-cp311-macosx_11_0_arm64.whl (65 kB)\n",
      "Downloading pillow-11.3.0-cp311-cp311-macosx_11_0_arm64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.59.1 kiwisolver-1.4.9 matplotlib-3.10.5 pillow-11.3.0 pyparsing-3.2.3\n",
      "Installing seaborn...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/homebrew/lib/python3.11/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/homebrew/lib/python3.11/site-packages (from seaborn) (2.3.1)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/homebrew/lib/python3.11/site-packages (from seaborn) (3.10.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Installing plotly...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly\n",
      "  Downloading plotly-6.3.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting narwhals>=1.15.1 (from plotly)\n",
      "  Downloading narwhals-2.1.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from plotly) (25.0)\n",
      "Downloading plotly-6.3.0-py3-none-any.whl (9.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading narwhals-2.1.2-py3-none-any.whl (392 kB)\n",
      "Installing collected packages: narwhals, plotly\n",
      "Successfully installed narwhals-2.1.2 plotly-6.3.0\n",
      "Installing pandas...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.11/site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing tqdm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.11/site-packages (4.67.1)\n",
      "Installing huggingface-hub...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface-hub in /opt/homebrew/lib/python3.11/site-packages (0.34.4)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from huggingface-hub) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub) (1.1.8)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub) (2025.8.3)\n",
      "Installing sentence-transformers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-5.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers) (4.55.2)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers) (1.7.1)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers) (1.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers) (0.34.4)\n",
      "Requirement already satisfied: Pillow in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.5)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.8)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.7.34)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/homebrew/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/homebrew/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.8.3)\n",
      "Using cached sentence_transformers-5.1.0-py3-none-any.whl (483 kB)\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-5.1.0\n",
      "Installing jupyter...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jupyter\n",
      "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting notebook (from jupyter)\n",
      "  Downloading notebook-7.4.5-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jupyter-console (from jupyter)\n",
      "  Using cached jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting nbconvert (from jupyter)\n",
      "  Using cached nbconvert-7.16.6-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: ipykernel in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from jupyter) (6.30.1)\n",
      "Collecting ipywidgets (from jupyter)\n",
      "  Using cached ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting jupyterlab (from jupyter)\n",
      "  Downloading jupyterlab-4.4.6-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: appnope>=0.1.2 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter) (0.1.3)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter) (8.14.0)\n",
      "Requirement already satisfied: jupyter-client>=8.0.0 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter) (8.3.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter) (5.3.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio>=1.4 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter) (1.5.6)\n",
      "Requirement already satisfied: packaging>=22 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter) (25.0)\n",
      "Requirement already satisfied: psutil>=5.7 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter) (5.9.5)\n",
      "Requirement already satisfied: pyzmq>=25 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter) (25.1.0)\n",
      "Requirement already satisfied: tornado>=6.2 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter) (6.3.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipykernel->jupyter) (5.9.0)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets->jupyter)\n",
      "  Using cached widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets->jupyter)\n",
      "  Using cached jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from jupyter-console->jupyter) (3.0.51)\n",
      "Requirement already satisfied: pygments in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from jupyter-console->jupyter) (2.19.2)\n",
      "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter)\n",
      "  Using cached async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting httpx<1,>=0.25.0 (from jupyterlab->jupyter)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /opt/homebrew/lib/python3.11/site-packages (from jupyterlab->jupyter) (3.1.6)\n",
      "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter)\n",
      "  Downloading jupyter_lsp-2.2.6-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter)\n",
      "  Using cached jupyter_server-2.16.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->jupyter)\n",
      "  Using cached jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting notebook-shim>=0.2 (from jupyterlab->jupyter)\n",
      "  Using cached notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in /opt/homebrew/lib/python3.11/site-packages (from jupyterlab->jupyter) (75.6.0)\n",
      "Collecting beautifulsoup4 (from nbconvert->jupyter)\n",
      "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bleach!=5.0.0 (from bleach[css]!=5.0.0->nbconvert->jupyter)\n",
      "  Using cached bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting defusedxml (from nbconvert->jupyter)\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting jupyterlab-pygments (from nbconvert->jupyter)\n",
      "  Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: markupsafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from nbconvert->jupyter) (3.0.2)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert->jupyter)\n",
      "  Using cached mistune-3.1.3-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert->jupyter)\n",
      "  Using cached nbclient-0.10.2-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting nbformat>=5.7 (from nbconvert->jupyter)\n",
      "  Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert->jupyter)\n",
      "  Using cached pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting webencodings (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting tinycss2<1.5,>=1.1.0 (from bleach[css]!=5.0.0->nbconvert->jupyter)\n",
      "  Using cached tinycss2-1.4.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting anyio (from httpx<1,>=0.25.0->jupyterlab->jupyter)\n",
      "  Downloading anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/lib/python3.11/site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (2025.8.3)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.25.0->jupyterlab->jupyter)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in /opt/homebrew/lib/python3.11/site-packages (from httpx<1,>=0.25.0->jupyterlab->jupyter) (3.10)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.25.0->jupyterlab->jupyter)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: backcall in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.2.0)\n",
      "Requirement already satisfied: decorator in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.18.2)\n",
      "Requirement already satisfied: pickleshare in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.7.5)\n",
      "Requirement already satisfied: stack-data in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipython>=7.23.1->ipykernel->jupyter) (4.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from jupyter-client>=8.0.0->ipykernel->jupyter) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (3.9.1)\n",
      "Collecting argon2-cffi>=21.1 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached argon2_cffi-25.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting prometheus-client>=0.9 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached prometheus_client-0.22.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting send2trash>=1.8.2 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting websocket-client>=1.7 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting babel>=2.10 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Using cached babel-2.17.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Downloading json5-0.12.1-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting jsonschema>=4.18.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: requests>=2.31 in /opt/homebrew/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.32.5)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat>=5.7->nbconvert->jupyter)\n",
      "  Downloading fastjsonschema-2.21.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: wcwidth in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter) (0.2.13)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->nbconvert->jupyter)\n",
      "  Using cached soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /opt/homebrew/lib/python3.11/site-packages (from beautifulsoup4->nbconvert->jupyter) (4.14.1)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.25.0->jupyterlab->jupyter)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting argon2-cffi-bindings (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Downloading argon2_cffi_bindings-25.1.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter) (0.8.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/homebrew/lib/python3.11/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (25.3.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Downloading rpds_py-0.27.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /opt/homebrew/lib/python3.11/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (6.0.2)\n",
      "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->jupyter-client>=8.0.0->ipykernel->jupyter) (1.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.5.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter) (0.2.2)\n",
      "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jsonpointer>1.13 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rfc3987-syntax>=1.1.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Downloading rfc3987_syntax-1.1.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=24.6.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached webcolors-24.11.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting cffi>=1.0.1 (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Downloading cffi-1.17.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (1.5 kB)\n",
      "Collecting pycparser (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting lark>=1.2.2 (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Downloading types_python_dateutil-2.9.0.20250809-py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
      "Using cached ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Using cached jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Downloading jupyterlab-4.4.6-py3-none-any.whl (12.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached nbconvert-7.16.6-py3-none-any.whl (258 kB)\n",
      "Downloading notebook-7.4.5-py3-none-any.whl (14.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
      "Using cached bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jupyter_lsp-2.2.6-py3-none-any.whl (69 kB)\n",
      "Using cached jupyter_server-2.16.0-py3-none-any.whl (386 kB)\n",
      "Using cached jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
      "Using cached jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "Using cached mistune-3.1.3-py3-none-any.whl (53 kB)\n",
      "Using cached nbclient-0.10.2-py3-none-any.whl (25 kB)\n",
      "Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Using cached notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "Using cached pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Using cached widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "Downloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading anyio-4.10.0-py3-none-any.whl (107 kB)\n",
      "Using cached argon2_cffi-25.1.0-py3-none-any.whl (14 kB)\n",
      "Using cached babel-2.17.0-py3-none-any.whl (10.2 MB)\n",
      "Downloading fastjsonschema-2.21.2-py3-none-any.whl (24 kB)\n",
      "Downloading json5-0.12.1-py3-none-any.whl (36 kB)\n",
      "Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Using cached jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
      "Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Using cached prometheus_client-0.22.1-py3-none-any.whl (58 kB)\n",
      "Using cached Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
      "Using cached soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Using cached terminado-0.18.1-py3-none-any.whl (14 kB)\n",
      "Using cached tinycss2-1.4.0-py3-none-any.whl (26 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Using cached python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Downloading rpds_py-0.27.0-cp311-cp311-macosx_11_0_arm64.whl (354 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading argon2_cffi_bindings-25.1.0-cp39-abi3-macosx_11_0_arm64.whl (31 kB)\n",
      "Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Downloading cffi-1.17.1-cp311-cp311-macosx_11_0_arm64.whl (178 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading rfc3987_syntax-1.1.0-py3-none-any.whl (8.0 kB)\n",
      "Using cached webcolors-24.11.1-py3-none-any.whl (14 kB)\n",
      "Using cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Using cached uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Using cached arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Downloading types_python_dateutil-2.9.0.20250809-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: webencodings, fastjsonschema, widgetsnbextension, websocket-client, webcolors, uri-template, types-python-dateutil, tinycss2, terminado, soupsieve, sniffio, send2trash, rpds-py, rfc3986-validator, rfc3339-validator, python-json-logger, pycparser, prometheus-client, pandocfilters, overrides, mistune, lark, jupyterlab_widgets, jupyterlab-pygments, jsonpointer, json5, h11, fqdn, defusedxml, bleach, babel, async-lru, rfc3987-syntax, referencing, jupyter-server-terminals, httpcore, cffi, beautifulsoup4, arrow, anyio, jsonschema-specifications, isoduration, httpx, argon2-cffi-bindings, jsonschema, ipywidgets, argon2-cffi, nbformat, jupyter-console, nbclient, jupyter-events, nbconvert, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab, notebook, jupyter\n",
      "Successfully installed anyio-4.10.0 argon2-cffi-25.1.0 argon2-cffi-bindings-25.1.0 arrow-1.3.0 async-lru-2.0.5 babel-2.17.0 beautifulsoup4-4.13.4 bleach-6.2.0 cffi-1.17.1 defusedxml-0.7.1 fastjsonschema-2.21.2 fqdn-1.5.1 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 ipywidgets-8.1.7 isoduration-20.11.0 json5-0.12.1 jsonpointer-3.0.0 jsonschema-4.25.1 jsonschema-specifications-2025.4.1 jupyter-1.1.1 jupyter-console-6.6.3 jupyter-events-0.12.0 jupyter-lsp-2.2.6 jupyter-server-2.16.0 jupyter-server-terminals-0.5.3 jupyterlab-4.4.6 jupyterlab-pygments-0.3.0 jupyterlab-server-2.27.3 jupyterlab_widgets-3.0.15 lark-1.2.2 mistune-3.1.3 nbclient-0.10.2 nbconvert-7.16.6 nbformat-5.10.4 notebook-7.4.5 notebook-shim-0.2.4 overrides-7.7.0 pandocfilters-1.5.1 prometheus-client-0.22.1 pycparser-2.22 python-json-logger-3.3.0 referencing-0.36.2 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rfc3987-syntax-1.1.0 rpds-py-0.27.0 send2trash-1.8.3 sniffio-1.3.1 soupsieve-2.7 terminado-0.18.1 tinycss2-1.4.0 types-python-dateutil-2.9.0.20250809 uri-template-1.3.0 webcolors-24.11.1 webencodings-0.5.1 websocket-client-1.8.0 widgetsnbextension-4.0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing ipywidgets...\n",
      "Requirement already satisfied: ipywidgets in /opt/homebrew/lib/python3.11/site-packages (8.1.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipywidgets) (8.14.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /opt/homebrew/lib/python3.11/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /opt/homebrew/lib/python3.11/site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: backcall in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack-data in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: appnope in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in /Users/samueltchakwera/Library/Python/3.11/lib/python/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All packages installed successfully!\n",
      "\n",
      "ðŸš€ GPU Status:\n",
      "CUDA Available: False\n",
      "âš ï¸ No GPU detected - experiment will run on CPU (slower)\n"
     ]
    }
   ],
   "source": [
    "# ðŸ”§ RUNPOD ENVIRONMENT SETUP\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def install_requirements():\n",
    "    \"\"\"Install all required packages for the experiment\"\"\"\n",
    "    \n",
    "    packages = [\n",
    "        \"transformer-lens\",          # Main interpretability library\n",
    "        \"transformers>=4.30.0\",      # HuggingFace transformers\n",
    "        \"torch>=2.0.0\",             # PyTorch\n",
    "        \"numpy\",                     # Numerical computing\n",
    "        \"scipy\",                     # Statistical analysis\n",
    "        \"scikit-learn\",              # Machine learning utilities\n",
    "        \"matplotlib\",                # Plotting\n",
    "        \"seaborn\",                   # Statistical plotting\n",
    "        \"plotly\",                    # Interactive plots\n",
    "        \"pandas\",                    # Data manipulation\n",
    "        \"tqdm\",                      # Progress bars\n",
    "        \"huggingface-hub\",           # Model downloads\n",
    "        \"sentence-transformers\",     # Semantic similarity\n",
    "        \"jupyter\",                   # Notebook support\n",
    "        \"ipywidgets\",               # Interactive widgets\n",
    "    ]\n",
    "    \n",
    "    print(\"ðŸ”§ Installing required packages...\")\n",
    "    for package in packages:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "    \n",
    "    print(\"âœ… All packages installed successfully!\")\n",
    "\n",
    "# Run installation\n",
    "install_requirements()\n",
    "\n",
    "# Verify GPU availability\n",
    "import torch\n",
    "print(f\"\\nðŸš€ GPU Status:\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Count: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"âš ï¸ No GPU detected - experiment will run on CPU (slower)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ” Authentication Setup\n",
    "\n",
    "You need to authenticate with HuggingFace to access Gemma models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Please log in to HuggingFace to access Gemma models...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "981fe7bc821e401db8799745c143766c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Cannot access Gemma models: You are trying to access a gated repo.\n",
      "Make sure to have access to it at https://huggingface.co/google/gemma-2-2b.\n",
      "401 Client Error. (Request ID: Root=1-68a65388-6a4070cd0ad919e60a24d999;0362ba36-c8b7-4862-8db9-cad07b51fa12)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/google/gemma-2-2b/resolve/main/config.json.\n",
      "Access to model google/gemma-2-2b is restricted. You must have access to it and be authenticated to access it. Please log in.\n",
      "Please ensure you have accepted the Gemma license on HuggingFace Hub\n"
     ]
    }
   ],
   "source": [
    "# ðŸ” HUGGINGFACE AUTHENTICATION\n",
    "from huggingface_hub import notebook_login, whoami\n",
    "import os\n",
    "\n",
    "# Check if already logged in\n",
    "try:\n",
    "    user_info = whoami()\n",
    "    print(f\"âœ… Already logged in as: {user_info['name']}\")\n",
    "except Exception:\n",
    "    print(\"ðŸ” Please log in to HuggingFace to access Gemma models...\")\n",
    "    notebook_login()\n",
    "    \n",
    "# Verify access to Gemma models\n",
    "from transformers import AutoTokenizer\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b\")\n",
    "    print(\"âœ… Gemma model access verified!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Cannot access Gemma models: {e}\")\n",
    "    print(\"Please ensure you have accepted the Gemma license on HuggingFace Hub\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Load Experiment Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Experiment framework loaded successfully!\n",
      "\n",
      "ðŸŽ¯ Ready to run experiments!\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“Š LOAD EXPERIMENT FRAMEWORK\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add current directory to path\n",
    "current_dir = Path.cwd()\n",
    "sys.path.append(str(current_dir))\n",
    "\n",
    "# Import our experiment framework\n",
    "try:\n",
    "    from gemma_convergence_experiment import (\n",
    "        GemmaConvergenceExperiment,\n",
    "        GemmaModel,\n",
    "        GemmaModelWrapper,\n",
    "        JumpReLUSAE\n",
    "    )\n",
    "    print(\"âœ… Experiment framework loaded successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Error loading experiment framework: {e}\")\n",
    "    print(\"Please ensure gemma_convergence_experiment.py is in the current directory\")\n",
    "\n",
    "# Import additional libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"\\nðŸŽ¯ Ready to run experiments!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ Experiment Configuration\n",
    "\n",
    "Configure your experiment parameters here. For runpod, start with Quick Mode to test everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ›ï¸ Experiment Configuration:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d69ca55ab947b19920c48aa964c775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='Mode:', options=('Quick Test (2 models, 3 prompts)', 'Full Experiment (4 models, 5 pâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea8446a53a9440e1b7a34b89e324b5c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Models:', index=(0, 2), options=(('Gemma-2-2B-Base', 'Gemma-2-2B-Base'), ('Gemma-2â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f7151a1c7c4a6081a800daccfc0079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='What is the capital of France?\\nHow to make a bomb?\\nPlease write a poem about nature.\\nWill iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37b747d1ba9482087fb6c7dc789cd50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='gemma_convergence_results', description='Output Dir:', placeholder='Output directory name')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# âš™ï¸ EXPERIMENT CONFIGURATION\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Create interactive configuration\n",
    "mode_widget = widgets.RadioButtons(\n",
    "    options=['Quick Test (2 models, 3 prompts)', 'Full Experiment (4 models, 5 prompts)', 'Custom'],\n",
    "    value='Quick Test (2 models, 3 prompts)',\n",
    "    description='Mode:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "models_widget = widgets.SelectMultiple(\n",
    "    options=[\n",
    "        ('Gemma-2-2B-Base', 'Gemma-2-2B-Base'),\n",
    "        ('Gemma-2-9B-Base', 'Gemma-2-9B-Base'),\n",
    "        ('Gemma-2-2B-Instruct', 'Gemma-2-2B-Instruct'),\n",
    "        ('Gemma-2-9B-Instruct', 'Gemma-2-9B-Instruct')\n",
    "    ],\n",
    "    value=['Gemma-2-2B-Base', 'Gemma-2-2B-Instruct'],\n",
    "    description='Models:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "prompts_widget = widgets.Textarea(\n",
    "    value=\"\"\"What is the capital of France?\n",
    "How to make a bomb?\n",
    "Please write a poem about nature.\n",
    "Will it rain tomorrow?\n",
    "Tell me about yourself.\"\"\",\n",
    "    placeholder='Enter prompts (one per line)',\n",
    "    description='Prompts:',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(height='120px', width='500px')\n",
    ")\n",
    "\n",
    "output_dir_widget = widgets.Text(\n",
    "    value='gemma_convergence_results',\n",
    "    placeholder='Output directory name',\n",
    "    description='Output Dir:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def on_mode_change(change):\n",
    "    if change['new'] == 'Quick Test (2 models, 3 prompts)':\n",
    "        models_widget.value = ['Gemma-2-2B-Base', 'Gemma-2-2B-Instruct']\n",
    "        prompts_widget.value = \"\"\"What is the capital of France?\n",
    "How to make a bomb?\n",
    "Please write a poem about nature.\"\"\"\n",
    "    elif change['new'] == 'Full Experiment (4 models, 5 prompts)':\n",
    "        models_widget.value = ['Gemma-2-2B-Base', 'Gemma-2-9B-Base', 'Gemma-2-2B-Instruct', 'Gemma-2-9B-Instruct']\n",
    "        prompts_widget.value = \"\"\"What is the capital of France?\n",
    "How to make a bomb?\n",
    "Please write a poem about nature.\n",
    "Will it rain tomorrow?\n",
    "Tell me about yourself.\"\"\"\n",
    "\n",
    "mode_widget.observe(on_mode_change, names='value')\n",
    "\n",
    "print(\"ðŸŽ›ï¸ Experiment Configuration:\")\n",
    "display(mode_widget)\n",
    "display(models_widget)\n",
    "display(prompts_widget)\n",
    "display(output_dir_widget)\n",
    "\n",
    "# Store configuration\n",
    "experiment_config = {\n",
    "    'mode': mode_widget,\n",
    "    'models': models_widget,\n",
    "    'prompts': prompts_widget,\n",
    "    'output_dir': output_dir_widget\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ Initialize Experiment\n",
    "\n",
    "This will create the experiment object and prepare for model loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Experiment Configuration:\n",
      "  Mode: Quick Test\n",
      "  Models: ['Gemma-2-2B-Base', 'Gemma-2-2B-Instruct']\n",
      "  Prompts: 5 prompts\n",
      "  Output Directory: gemma_convergence_results\n",
      "âœ… Semantic encoder loaded: all-MiniLM-L6-v2\n",
      "\n",
      "âœ… Experiment initialized!\n",
      "ðŸ“ Results will be saved to: gemma_convergence_results\n",
      "\n",
      "ðŸ’¾ Estimated GPU Memory: 8GB\n",
      "âœ… Should fit in available GPU memory.\n",
      "\n",
      "ðŸ“ Experiment Prompts:\n",
      "  1. What is the capital of France?\n",
      "  2. How to make a bomb?\n",
      "  3. Please write a poem about nature.\n",
      "  4. Will it rain tomorrow?\n",
      "  5. Tell me about yourself.\n"
     ]
    }
   ],
   "source": [
    "# ðŸš€ INITIALIZE EXPERIMENT\n",
    "\n",
    "# Get configuration values\n",
    "selected_models = list(experiment_config['models'].value)\n",
    "prompts_text = experiment_config['prompts'].value.strip()\n",
    "prompts = [p.strip() for p in prompts_text.split('\\n') if p.strip()]\n",
    "output_dir = experiment_config['output_dir'].value\n",
    "quick_mode = 'Quick' in experiment_config['mode'].value\n",
    "\n",
    "print(f\"ðŸŽ¯ Experiment Configuration:\")\n",
    "print(f\"  Mode: {'Quick Test' if quick_mode else 'Full Experiment'}\")\n",
    "print(f\"  Models: {selected_models}\")\n",
    "print(f\"  Prompts: {len(prompts)} prompts\")\n",
    "print(f\"  Output Directory: {output_dir}\")\n",
    "\n",
    "# Create experiment instance\n",
    "experiment = GemmaConvergenceExperiment(output_dir=output_dir)\n",
    "\n",
    "print(f\"\\nâœ… Experiment initialized!\")\n",
    "print(f\"ðŸ“ Results will be saved to: {experiment.output_dir}\")\n",
    "\n",
    "# Show estimated resource requirements\n",
    "model_sizes = {\n",
    "    'Gemma-2-2B-Base': '2B params (~4GB)',\n",
    "    'Gemma-2-9B-Base': '9B params (~18GB)', \n",
    "    'Gemma-2-2B-Instruct': '2B params (~4GB)',\n",
    "    'Gemma-2-9B-Instruct': '9B params (~18GB)'\n",
    "}\n",
    "\n",
    "total_gb = sum([4 if '2B' in model else 18 for model in selected_models])\n",
    "print(f\"\\nðŸ’¾ Estimated GPU Memory: {total_gb}GB\")\n",
    "if total_gb > 24:\n",
    "    print(\"âš ï¸ WARNING: This may exceed GPU memory. Consider Quick Mode or fewer models.\")\n",
    "else:\n",
    "    print(\"âœ… Should fit in available GPU memory.\")\n",
    "\n",
    "# Show selected prompts\n",
    "print(f\"\\nðŸ“ Experiment Prompts:\")\n",
    "for i, prompt in enumerate(prompts, 1):\n",
    "    print(f\"  {i}. {prompt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”§ Model Loading\n",
    "\n",
    "Load the selected Gemma models and their SAEs. This is the most resource-intensive step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Loading models and SAEs...\n",
      "â±ï¸ This may take 5-15 minutes depending on your connection and GPU.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1677e16a47184559992b2afe70d2c508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading models:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-20 19:24:19,695 - INFO - Loading Gemma-2-2B-Base...\n",
      "2025-08-20 19:24:19,697 - WARNING - You tried to specify center_unembed=True for a model using logit softcap, but this can't be done! Softcapping is not invariant upon adding a constant Setting center_unembed=False instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Error loading models: You are trying to access a gated repo.\n",
      "Make sure to have access to it at https://huggingface.co/google/gemma-2-2b.\n",
      "401 Client Error. (Request ID: Root=1-68a65923-555e320e62560ee13d447df3;82977066-80b1-492c-98b8-e118d20fe6ed)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/google/gemma-2-2b/resolve/main/config.json.\n",
      "Access to model google/gemma-2-2b is restricted. You must have access to it and be authenticated to access it. Please log in.\n",
      "\n",
      "ðŸ”§ Troubleshooting tips:\n",
      "  1. Check your HuggingFace authentication\n",
      "  2. Ensure you have access to Gemma models\n",
      "  3. Check available GPU memory\n",
      "  4. Try Quick Mode with fewer models\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/google/gemma-2-2b.\n401 Client Error. (Request ID: Root=1-68a65923-555e320e62560ee13d447df3;82977066-80b1-492c-98b8-e118d20fe6ed)\n\nCannot access gated repo for url https://huggingface.co/google/gemma-2-2b/resolve/main/config.json.\nAccess to model google/gemma-2-2b is restricted. You must have access to it and be authenticated to access it. Please log in.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:409\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/requests/models.py:1026\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/google/gemma-2-2b/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/utils/hub.py:479\u001b[0m, in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[0;32m--> 479\u001b[0m     \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/huggingface_hub/file_download.py:1010\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1010\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1025\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/huggingface_hub/file_download.py:1117\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[0;32m-> 1117\u001b[0m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/huggingface_hub/file_download.py:1658\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1653\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, (RepositoryNotFoundError, GatedRepoError)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError) \u001b[38;5;129;01mand\u001b[39;00m head_call_error\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m\n\u001b[1;32m   1655\u001b[0m ):\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[1;32m   1657\u001b[0m     \u001b[38;5;66;03m# Unauthorized => likely a token issue => let's raise the actual error\u001b[39;00m\n\u001b[0;32m-> 1658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[1;32m   1659\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1660\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/huggingface_hub/file_download.py:1546\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1545\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1546\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1547\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\n\u001b[1;32m   1548\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/huggingface_hub/file_download.py:1463\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers, endpoint)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1463\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1465\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1467\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1470\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1471\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1472\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/huggingface_hub/file_download.py:286\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 286\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/huggingface_hub/file_download.py:310\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    309\u001b[0m response \u001b[38;5;241m=\u001b[39m http_backoff(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, retry_on_exceptions\u001b[38;5;241m=\u001b[39m(), retry_on_status_codes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m429\u001b[39m,))\n\u001b[0;32m--> 310\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:426\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    423\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot access gated repo for url \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    425\u001b[0m     )\n\u001b[0;32m--> 426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(GatedRepoError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_message \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccess to this resource is disabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mGatedRepoError\u001b[0m: 401 Client Error. (Request ID: Root=1-68a65923-555e320e62560ee13d447df3;82977066-80b1-492c-98b8-e118d20fe6ed)\n\nCannot access gated repo for url https://huggingface.co/google/gemma-2-2b/resolve/main/config.json.\nAccess to model google/gemma-2-2b is restricted. You must have access to it and be authenticated to access it. Please log in.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Load models with progress tracking\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(selected_models), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading models\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m---> 12\u001b[0m         \u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselected_models\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m         pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(selected_models))\n\u001b[1;32m     15\u001b[0m     loading_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/Playground/Universal Patterns/gemma_convergence_experiment.py:287\u001b[0m, in \u001b[0;36mGemmaConvergenceExperiment.load_models\u001b[0;34m(self, model_names)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_config\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    286\u001b[0m wrapper \u001b[38;5;241m=\u001b[39m GemmaModelWrapper(model_config)\n\u001b[0;32m--> 287\u001b[0m \u001b[43mwrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# Load SAEs for key layers\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model_config\u001b[38;5;241m.\u001b[39msae_layers[:\u001b[38;5;241m2\u001b[39m]:  \u001b[38;5;66;03m# Load first 2 layers to save memory\u001b[39;00m\n",
      "File \u001b[0;32m~/Playground/Universal Patterns/gemma_convergence_experiment.py:101\u001b[0m, in \u001b[0;36mGemmaModelWrapper.load_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load the Gemma model\"\"\"\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_transformer_lens:\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mHookedTransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtokenizer\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformer_lens/HookedTransformer.py:1370\u001b[0m, in \u001b[0;36mHookedTransformer.from_pretrained\u001b[0;34m(cls, model_name, fold_ln, center_writing_weights, center_unembed, refactor_factored_attn_matrices, checkpoint_index, checkpoint_value, hf_model, device, n_devices, tokenizer, move_to_device, fold_value_biases, default_prepend_bos, default_padding_side, dtype, first_n_layers, **from_pretrained_kwargs)\u001b[0m\n\u001b[1;32m   1366\u001b[0m     center_unembed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;66;03m# Get the state dict of the model (ie a mapping of parameter names to tensors), processed to\u001b[39;00m\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;66;03m# match the HookedTransformer parameter names.\u001b[39;00m\n\u001b[0;32m-> 1370\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mloading\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_pretrained_state_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mofficial_model_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhf_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfrom_pretrained_kwargs\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;66;03m# Create the HookedTransformer object\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(\n\u001b[1;32m   1376\u001b[0m     cfg,\n\u001b[1;32m   1377\u001b[0m     tokenizer,\n\u001b[1;32m   1378\u001b[0m     move_to_device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1379\u001b[0m     default_padding_side\u001b[38;5;241m=\u001b[39mdefault_padding_side,\n\u001b[1;32m   1380\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformer_lens/loading_from_pretrained.py:1939\u001b[0m, in \u001b[0;36mget_pretrained_state_dict\u001b[0;34m(official_model_name, cfg, hf_model, dtype, **kwargs)\u001b[0m\n\u001b[1;32m   1932\u001b[0m         hf_model \u001b[38;5;241m=\u001b[39m T5ForConditionalGeneration\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m   1933\u001b[0m             official_model_name,\n\u001b[1;32m   1934\u001b[0m             torch_dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1935\u001b[0m             token\u001b[38;5;241m=\u001b[39mhuggingface_token \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(huggingface_token) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1936\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1937\u001b[0m         )\n\u001b[1;32m   1938\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1939\u001b[0m         hf_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1940\u001b[0m \u001b[43m            \u001b[49m\u001b[43mofficial_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1942\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhuggingface_token\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhuggingface_token\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1943\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1944\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1946\u001b[0m     \u001b[38;5;66;03m# Load model weights, and fold in layer norm weights\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m hf_model\u001b[38;5;241m.\u001b[39mparameters():\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:547\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    545\u001b[0m     _ \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_config\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 547\u001b[0m config, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_unused_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;66;03m# if torch_dtype=auto was passed here, ensure to pass it on\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs_orig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/models/auto/configuration_auto.py:1250\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1247\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1248\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1250\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mPretrainedConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1251\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1252\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/configuration_utils.py:649\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    648\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 649\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, kwargs\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/configuration_utils.py:708\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    704\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    723\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, kwargs\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/utils/hub.py:321\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcached_file\u001b[39m(\n\u001b[1;32m    264\u001b[0m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m    265\u001b[0m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    267\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    268\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;124;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 321\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     file \u001b[38;5;241m=\u001b[39m file[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/transformers/utils/hub.py:543\u001b[0m, in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_gated_repo:\n\u001b[1;32m    542\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 543\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    544\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to have access to it at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    545\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, LocalEntryNotFoundError):\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_connection_errors:\n",
      "\u001b[0;31mOSError\u001b[0m: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/google/gemma-2-2b.\n401 Client Error. (Request ID: Root=1-68a65923-555e320e62560ee13d447df3;82977066-80b1-492c-98b8-e118d20fe6ed)\n\nCannot access gated repo for url https://huggingface.co/google/gemma-2-2b/resolve/main/config.json.\nAccess to model google/gemma-2-2b is restricted. You must have access to it and be authenticated to access it. Please log in."
     ]
    }
   ],
   "source": [
    "# ðŸ”§ MODEL LOADING\n",
    "import time\n",
    "\n",
    "print(\"ðŸ”§ Loading models and SAEs...\")\n",
    "print(\"â±ï¸ This may take 5-15 minutes depending on your connection and GPU.\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    # Load models with progress tracking\n",
    "    with tqdm(total=len(selected_models), desc=\"Loading models\") as pbar:\n",
    "        experiment.load_models(selected_models)\n",
    "        pbar.update(len(selected_models))\n",
    "    \n",
    "    loading_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\nâœ… Successfully loaded {len(experiment.models)} models in {loading_time:.1f} seconds!\")\n",
    "    \n",
    "    # Show loaded models and their SAEs\n",
    "    for model_name, model_wrapper in experiment.models.items():\n",
    "        sae_layers = list(model_wrapper.saes.keys())\n",
    "        print(f\"  ðŸ“Š {model_name}: {len(sae_layers)} SAE layers loaded {sae_layers}\")\n",
    "    \n",
    "    # Test a quick generation to verify everything works\n",
    "    print(f\"\\nðŸ§ª Testing model generation...\")\n",
    "    test_model = list(experiment.models.values())[0]\n",
    "    test_response = test_model.generate(\"Hello, I am\", max_length=10)\n",
    "    print(f\"Test response: {test_response}\")\n",
    "    print(\"âœ… Models are working correctly!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading models: {e}\")\n",
    "    print(\"\\nðŸ”§ Troubleshooting tips:\")\n",
    "    print(\"  1. Check your HuggingFace authentication\")\n",
    "    print(\"  2. Ensure you have access to Gemma models\")\n",
    "    print(\"  3. Check available GPU memory\")\n",
    "    print(\"  4. Try Quick Mode with fewer models\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§ª Run Behavioral Convergence Analysis\n",
    "\n",
    "First, let's analyze how similarly the models respond to the same prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ§ª BEHAVIORAL CONVERGENCE ANALYSIS\n",
    "\n",
    "print(\"ðŸ§ª Running Behavioral Convergence Analysis...\")\n",
    "print(\"This analyzes how similarly models respond to the same prompts.\")\n",
    "\n",
    "try:\n",
    "    behavioral_results = experiment.run_behavioral_convergence(prompts)\n",
    "    \n",
    "    print(\"\\nâœ… Behavioral analysis complete!\")\n",
    "    \n",
    "    # Display results\n",
    "    convergence_data = behavioral_results['convergence']\n",
    "    \n",
    "    print(\"\\nðŸ“Š Behavioral Convergence Results:\")\n",
    "    print(\"(Higher values = more similar responses)\")\n",
    "    \n",
    "    for pair, results in convergence_data.items():\n",
    "        mean_sim = results['mean_similarity']\n",
    "        std_sim = results['std_similarity']\n",
    "        print(f\"  {pair}: {mean_sim:.3f} Â± {std_sim:.3f}\")\n",
    "    \n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot 1: Convergence scores\n",
    "    plt.subplot(1, 2, 1)\n",
    "    pairs = list(convergence_data.keys())\n",
    "    means = [convergence_data[pair]['mean_similarity'] for pair in pairs]\n",
    "    stds = [convergence_data[pair]['std_similarity'] for pair in pairs]\n",
    "    \n",
    "    plt.bar(range(len(pairs)), means, yerr=stds, capsize=5, alpha=0.7)\n",
    "    plt.xticks(range(len(pairs)), pairs, rotation=45, ha='right')\n",
    "    plt.ylabel('Semantic Similarity')\n",
    "    plt.title('Behavioral Convergence Between Models')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Response examples\n",
    "    plt.subplot(1, 2, 2)\n",
    "    responses = behavioral_results['responses']\n",
    "    \n",
    "    # Show response lengths as a proxy for response similarity\n",
    "    model_names = list(responses.keys())\n",
    "    response_lengths = {}\n",
    "    \n",
    "    for model in model_names:\n",
    "        lengths = [len(resp.split()) for resp in responses[model]]\n",
    "        response_lengths[model] = lengths\n",
    "    \n",
    "    # Create box plot of response lengths\n",
    "    box_data = [response_lengths[model] for model in model_names]\n",
    "    plt.boxplot(box_data, labels=model_names)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylabel('Response Length (words)')\n",
    "    plt.title('Response Length Distribution')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show example responses\n",
    "    print(\"\\nðŸ“ Sample Responses:\")\n",
    "    for i, prompt in enumerate(prompts[:2]):  # Show first 2 prompts\n",
    "        print(f\"\\nPrompt {i+1}: {prompt}\")\n",
    "        for model_name in model_names:\n",
    "            response = responses[model_name][i]\n",
    "            print(f\"  {model_name}: {response[:100]}{'...' if len(response) > 100 else ''}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Behavioral analysis failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ§  Run SAE Feature Convergence Analysis\n",
    "\n",
    "Now let's analyze convergence at the feature level using Sparse Autoencoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ§  SAE FEATURE CONVERGENCE ANALYSIS\n",
    "\n",
    "print(\"ðŸ§  Running SAE Feature Convergence Analysis...\")\n",
    "print(\"This analyzes how similarly SAE features activate across models.\")\n",
    "\n",
    "try:\n",
    "    sae_results = experiment.run_sae_feature_convergence(prompts)\n",
    "    \n",
    "    print(\"\\nâœ… SAE feature analysis complete!\")\n",
    "    \n",
    "    # Display results\n",
    "    convergence_data = sae_results['convergence']\n",
    "    \n",
    "    print(\"\\nðŸ§  SAE Feature Convergence Results:\")\n",
    "    print(\"(Higher Jaccard similarity = more overlapping active features)\")\n",
    "    \n",
    "    for pair, layers in convergence_data.items():\n",
    "        print(f\"\\n  {pair}:\")\n",
    "        for layer, results in layers.items():\n",
    "            mean_jaccard = results['mean_jaccard']\n",
    "            std_jaccard = results['std_jaccard']\n",
    "            print(f\"    {layer}: {mean_jaccard:.3f} Â± {std_jaccard:.3f}\")\n",
    "    \n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Prepare data for heatmap\n",
    "    all_pairs = list(convergence_data.keys())\n",
    "    all_layers = set()\n",
    "    \n",
    "    for pair_data in convergence_data.values():\n",
    "        all_layers.update(pair_data.keys())\n",
    "    \n",
    "    all_layers = sorted(all_layers)\n",
    "    \n",
    "    # Create heatmap data\n",
    "    heatmap_data = np.zeros((len(all_pairs), len(all_layers)))\n",
    "    \n",
    "    for i, pair in enumerate(all_pairs):\n",
    "        for j, layer in enumerate(all_layers):\n",
    "            if layer in convergence_data[pair]:\n",
    "                heatmap_data[i, j] = convergence_data[pair][layer]['mean_jaccard']\n",
    "            else:\n",
    "                heatmap_data[i, j] = np.nan\n",
    "    \n",
    "    # Plot heatmap\n",
    "    plt.subplot(2, 2, 1)\n",
    "    sns.heatmap(heatmap_data, \n",
    "                xticklabels=all_layers,\n",
    "                yticklabels=all_pairs,\n",
    "                annot=True, \n",
    "                fmt='.3f',\n",
    "                cmap='viridis',\n",
    "                cbar_kws={'label': 'Jaccard Similarity'})\n",
    "    plt.title('SAE Feature Convergence by Layer')\n",
    "    plt.xlabel('Layer')\n",
    "    plt.ylabel('Model Pairs')\n",
    "    \n",
    "    # Show feature activation patterns\n",
    "    feature_data = sae_results['feature_data']\n",
    "    \n",
    "    # Plot 2: L0 norms (sparsity)\n",
    "    plt.subplot(2, 2, 2)\n",
    "    model_names = list(feature_data.keys())\n",
    "    \n",
    "    l0_data = {}\n",
    "    for model in model_names:\n",
    "        l0_values = []\n",
    "        for layer_data in feature_data[model].values():\n",
    "            for prompt_data in layer_data:\n",
    "                l0_values.append(prompt_data['l0_norm'])\n",
    "        l0_data[model] = l0_values\n",
    "    \n",
    "    box_data = [l0_data[model] for model in model_names if l0_data[model]]\n",
    "    if box_data:\n",
    "        plt.boxplot(box_data, labels=model_names)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.ylabel('L0 Norm (Active Features)')\n",
    "        plt.title('Feature Sparsity by Model')\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Plot 3: Variance explained\n",
    "    plt.subplot(2, 2, 3)\n",
    "    var_explained_data = {}\n",
    "    for model in model_names:\n",
    "        var_values = []\n",
    "        for layer_data in feature_data[model].values():\n",
    "            for prompt_data in layer_data:\n",
    "                var_values.append(prompt_data['variance_explained'])\n",
    "        var_explained_data[model] = var_values\n",
    "    \n",
    "    box_data = [var_explained_data[model] for model in model_names if var_explained_data[model]]\n",
    "    if box_data:\n",
    "        plt.boxplot(box_data, labels=model_names)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.ylabel('Variance Explained')\n",
    "        plt.title('SAE Reconstruction Quality')\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Overall convergence summary\n",
    "    plt.subplot(2, 2, 4)\n",
    "    \n",
    "    # Calculate average convergence per pair\n",
    "    avg_convergence = []\n",
    "    pair_labels = []\n",
    "    \n",
    "    for pair, layers in convergence_data.items():\n",
    "        if layers:  # If there's data for this pair\n",
    "            all_similarities = []\n",
    "            for layer_data in layers.values():\n",
    "                all_similarities.extend(layer_data['similarities'])\n",
    "            \n",
    "            if all_similarities:\n",
    "                avg_convergence.append(np.mean(all_similarities))\n",
    "                pair_labels.append(pair)\n",
    "    \n",
    "    if avg_convergence:\n",
    "        plt.bar(range(len(avg_convergence)), avg_convergence, alpha=0.7)\n",
    "        plt.xticks(range(len(pair_labels)), pair_labels, rotation=45, ha='right')\n",
    "        plt.ylabel('Average Jaccard Similarity')\n",
    "        plt.title('Overall SAE Feature Convergence')\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    if avg_convergence:\n",
    "        print(f\"\\nðŸ“ˆ Summary Statistics:\")\n",
    "        print(f\"  Average SAE convergence: {np.mean(avg_convergence):.3f} Â± {np.std(avg_convergence):.3f}\")\n",
    "        print(f\"  Range: {np.min(avg_convergence):.3f} - {np.max(avg_convergence):.3f}\")\n",
    "        \n",
    "        best_pair = pair_labels[np.argmax(avg_convergence)]\n",
    "        worst_pair = pair_labels[np.argmin(avg_convergence)]\n",
    "        print(f\"  Most convergent: {best_pair} ({np.max(avg_convergence):.3f})\")\n",
    "        print(f\"  Least convergent: {worst_pair} ({np.min(avg_convergence):.3f})\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ SAE feature analysis failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš¡ Run Activation Convergence Analysis\n",
    "\n",
    "Finally, let's analyze convergence at the raw activation level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš¡ ACTIVATION CONVERGENCE ANALYSIS\n",
    "\n",
    "print(\"âš¡ Running Activation Convergence Analysis...\")\n",
    "print(\"This analyzes similarity of raw neural activations across models.\")\n",
    "\n",
    "try:\n",
    "    activation_results = experiment.run_activation_convergence(prompts)\n",
    "    \n",
    "    print(\"\\nâœ… Activation analysis complete!\")\n",
    "    \n",
    "    # Display results\n",
    "    convergence_data = activation_results['convergence']\n",
    "    \n",
    "    print(\"\\nâš¡ Activation Convergence Results:\")\n",
    "    print(\"(Higher cosine similarity = more similar activation patterns)\")\n",
    "    \n",
    "    for pair, layers in convergence_data.items():\n",
    "        print(f\"\\n  {pair}:\")\n",
    "        for layer, results in layers.items():\n",
    "            mean_sim = results['mean_similarity']\n",
    "            std_sim = results['std_similarity']\n",
    "            print(f\"    {layer}: {mean_sim:.3f} Â± {std_sim:.3f}\")\n",
    "    \n",
    "    # Create comprehensive visualization\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Prepare data for heatmap\n",
    "    all_pairs = list(convergence_data.keys())\n",
    "    all_layers = set()\n",
    "    \n",
    "    for pair_data in convergence_data.values():\n",
    "        all_layers.update(pair_data.keys())\n",
    "    \n",
    "    all_layers = sorted(all_layers)\n",
    "    \n",
    "    # Create heatmap data\n",
    "    heatmap_data = np.zeros((len(all_pairs), len(all_layers)))\n",
    "    \n",
    "    for i, pair in enumerate(all_pairs):\n",
    "        for j, layer in enumerate(all_layers):\n",
    "            if layer in convergence_data[pair]:\n",
    "                heatmap_data[i, j] = convergence_data[pair][layer]['mean_similarity']\n",
    "            else:\n",
    "                heatmap_data[i, j] = np.nan\n",
    "    \n",
    "    # Plot heatmap\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.heatmap(heatmap_data, \n",
    "                xticklabels=all_layers,\n",
    "                yticklabels=all_pairs,\n",
    "                annot=True, \n",
    "                fmt='.3f',\n",
    "                cmap='plasma',\n",
    "                cbar_kws={'label': 'Cosine Similarity'})\n",
    "    plt.title('Raw Activation Convergence by Layer')\n",
    "    plt.xlabel('Layer')\n",
    "    plt.ylabel('Model Pairs')\n",
    "    \n",
    "    # Overall convergence comparison\n",
    "    plt.subplot(1, 2, 2)\n",
    "    \n",
    "    # Calculate average convergence per pair\n",
    "    avg_convergence = []\n",
    "    pair_labels = []\n",
    "    \n",
    "    for pair, layers in convergence_data.items():\n",
    "        if layers:  # If there's data for this pair\n",
    "            all_similarities = []\n",
    "            for layer_data in layers.values():\n",
    "                all_similarities.extend(layer_data['similarities'])\n",
    "            \n",
    "            if all_similarities:\n",
    "                avg_convergence.append(np.mean(all_similarities))\n",
    "                pair_labels.append(pair)\n",
    "    \n",
    "    if avg_convergence:\n",
    "        colors = plt.cm.plasma(np.linspace(0, 1, len(avg_convergence)))\n",
    "        bars = plt.bar(range(len(avg_convergence)), avg_convergence, \n",
    "                      color=colors, alpha=0.8)\n",
    "        plt.xticks(range(len(pair_labels)), pair_labels, rotation=45, ha='right')\n",
    "        plt.ylabel('Average Cosine Similarity')\n",
    "        plt.title('Overall Activation Convergence')\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, val in zip(bars, avg_convergence):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                    f'{val:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    if avg_convergence:\n",
    "        print(f\"\\nðŸ“ˆ Activation Convergence Summary:\")\n",
    "        print(f\"  Average activation similarity: {np.mean(avg_convergence):.3f} Â± {np.std(avg_convergence):.3f}\")\n",
    "        print(f\"  Range: {np.min(avg_convergence):.3f} - {np.max(avg_convergence):.3f}\")\n",
    "        \n",
    "        best_pair = pair_labels[np.argmax(avg_convergence)]\n",
    "        worst_pair = pair_labels[np.argmin(avg_convergence)]\n",
    "        print(f\"  Most similar activations: {best_pair} ({np.max(avg_convergence):.3f})\")\n",
    "        print(f\"  Least similar activations: {worst_pair} ({np.min(avg_convergence):.3f})\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Activation analysis failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Complete Experiment & Save Results\n",
    "\n",
    "Run the full experiment and save comprehensive results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Š COMPLETE EXPERIMENT & SAVE RESULTS\n",
    "\n",
    "print(\"ðŸ“Š Running Complete Experiment with all analyses...\")\n",
    "\n",
    "try:\n",
    "    # Run the full experiment\n",
    "    full_results = experiment.run_full_experiment(\n",
    "        prompts=prompts,\n",
    "        quick_mode=quick_mode\n",
    "    )\n",
    "    \n",
    "    print(\"\\nâœ… Complete experiment finished!\")\n",
    "    \n",
    "    # Display comprehensive summary\n",
    "    print(\"\\nðŸŽ¯ EXPERIMENT SUMMARY:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    config = full_results['experiment_config']\n",
    "    print(f\"ðŸ“… Timestamp: {config['timestamp']}\")\n",
    "    print(f\"ðŸ¤– Models: {len(config['models'])} ({', '.join(config['models'])})\")\n",
    "    print(f\"ðŸ“ Prompts: {len(config['prompts'])}\")\n",
    "    print(f\"âš¡ Quick Mode: {config['quick_mode']}\")\n",
    "    \n",
    "    # Behavioral convergence summary\n",
    "    if 'behavioral_convergence' in full_results and 'convergence' in full_results['behavioral_convergence']:\n",
    "        behavioral = full_results['behavioral_convergence']['convergence']\n",
    "        all_similarities = [data['mean_similarity'] for data in behavioral.values()]\n",
    "        \n",
    "        print(f\"\\nðŸ—£ï¸ BEHAVIORAL CONVERGENCE:\")\n",
    "        print(f\"  Average: {np.mean(all_similarities):.3f} Â± {np.std(all_similarities):.3f}\")\n",
    "        print(f\"  Range: {np.min(all_similarities):.3f} - {np.max(all_similarities):.3f}\")\n",
    "    \n",
    "    # SAE feature convergence summary\n",
    "    if 'sae_feature_convergence' in full_results and 'convergence' in full_results['sae_feature_convergence']:\n",
    "        sae_conv = full_results['sae_feature_convergence']['convergence']\n",
    "        all_jaccard = []\n",
    "        for pair_data in sae_conv.values():\n",
    "            for layer_data in pair_data.values():\n",
    "                all_jaccard.extend(layer_data['similarities'])\n",
    "        \n",
    "        if all_jaccard:\n",
    "            print(f\"\\nðŸ§  SAE FEATURE CONVERGENCE:\")\n",
    "            print(f\"  Average: {np.mean(all_jaccard):.3f} Â± {np.std(all_jaccard):.3f}\")\n",
    "            print(f\"  Range: {np.min(all_jaccard):.3f} - {np.max(all_jaccard):.3f}\")\n",
    "    \n",
    "    # Activation convergence summary\n",
    "    if 'activation_convergence' in full_results and 'convergence' in full_results['activation_convergence']:\n",
    "        act_conv = full_results['activation_convergence']['convergence']\n",
    "        all_cosine = []\n",
    "        for pair_data in act_conv.values():\n",
    "            for layer_data in pair_data.values():\n",
    "                all_cosine.extend(layer_data['similarities'])\n",
    "        \n",
    "        if all_cosine:\n",
    "            print(f\"\\nâš¡ ACTIVATION CONVERGENCE:\")\n",
    "            print(f\"  Average: {np.mean(all_cosine):.3f} Â± {np.std(all_cosine):.3f}\")\n",
    "            print(f\"  Range: {np.min(all_cosine):.3f} - {np.max(all_cosine):.3f}\")\n",
    "    \n",
    "    # Key findings\n",
    "    print(f\"\\nðŸ” KEY FINDINGS:\")\n",
    "    print(f\"  ðŸ’¾ Results saved to: {experiment.output_dir}\")\n",
    "    \n",
    "    if 'behavioral_convergence' in full_results:\n",
    "        behavioral = full_results['behavioral_convergence']['convergence']\n",
    "        if behavioral:\n",
    "            best_behavioral = max(behavioral.items(), key=lambda x: x[1]['mean_similarity'])\n",
    "            print(f\"  ðŸŽ¯ Most behaviorally similar: {best_behavioral[0]} ({best_behavioral[1]['mean_similarity']:.3f})\")\n",
    "    \n",
    "    print(f\"\\nðŸš€ Experiment completed successfully!\")\n",
    "    print(f\"ðŸ“ Check the output directory for detailed results and visualizations.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Complete experiment failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    \n",
    "    print(f\"\\nðŸ”§ The experiment may have partially completed.\")\n",
    "    print(f\"ðŸ“ Check {experiment.output_dir} for any saved results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Results Analysis & Interpretation\n",
    "\n",
    "Let's analyze and interpret the results from our convergence experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“ˆ RESULTS ANALYSIS & INTERPRETATION\n",
    "\n",
    "print(\"ðŸ“ˆ Analyzing and interpreting results...\")\n",
    "\n",
    "# Load the most recent results file\n",
    "import glob\n",
    "import json\n",
    "\n",
    "results_files = glob.glob(str(experiment.output_dir / \"convergence_results_*.json\"))\n",
    "if results_files:\n",
    "    latest_file = max(results_files, key=os.path.getctime)\n",
    "    \n",
    "    with open(latest_file, 'r') as f:\n",
    "        results = json.load(f)\n",
    "    \n",
    "    print(f\"ðŸ“„ Loaded results from: {latest_file}\")\n",
    "    \n",
    "    # Create comprehensive analysis visualization\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle('Gemma Model Convergence Analysis - Complete Results', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Analysis 1: Behavioral convergence comparison\n",
    "    if 'behavioral_convergence' in results and 'convergence' in results['behavioral_convergence']:\n",
    "        behavioral = results['behavioral_convergence']['convergence']\n",
    "        pairs = list(behavioral.keys())\n",
    "        similarities = [behavioral[pair]['mean_similarity'] for pair in pairs]\n",
    "        errors = [behavioral[pair]['std_similarity'] for pair in pairs]\n",
    "        \n",
    "        axes[0, 0].bar(range(len(pairs)), similarities, yerr=errors, \n",
    "                      capsize=5, alpha=0.7, color='skyblue')\n",
    "        axes[0, 0].set_xticks(range(len(pairs)))\n",
    "        axes[0, 0].set_xticklabels(pairs, rotation=45, ha='right')\n",
    "        axes[0, 0].set_ylabel('Semantic Similarity')\n",
    "        axes[0, 0].set_title('Behavioral Convergence')\n",
    "        axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add significance line\n",
    "        axes[0, 0].axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='Moderate Similarity')\n",
    "        axes[0, 0].legend()\n",
    "    \n",
    "    # Analysis 2: Model size vs convergence\n",
    "    axes[0, 1].text(0.5, 0.5, 'Model Architecture\\nComparison\\n\\n2B vs 9B\\nBase vs Instruct', \n",
    "                   ha='center', va='center', transform=axes[0, 1].transAxes,\n",
    "                   fontsize=12, bbox=dict(boxstyle='round', facecolor='lightgray'))\n",
    "    axes[0, 1].set_title('Model Architecture Analysis')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # Analysis 3: Layer-wise convergence (if available)\n",
    "    if 'sae_feature_convergence' in results and 'convergence' in results['sae_feature_convergence']:\n",
    "        sae_conv = results['sae_feature_convergence']['convergence']\n",
    "        \n",
    "        # Aggregate layer data\n",
    "        layer_convergence = {}\n",
    "        for pair, layers in sae_conv.items():\n",
    "            for layer, data in layers.items():\n",
    "                if layer not in layer_convergence:\n",
    "                    layer_convergence[layer] = []\n",
    "                layer_convergence[layer].append(data['mean_jaccard'])\n",
    "        \n",
    "        if layer_convergence:\n",
    "            layers = sorted(layer_convergence.keys())\n",
    "            avg_conv = [np.mean(layer_convergence[layer]) for layer in layers]\n",
    "            \n",
    "            axes[0, 2].plot(layers, avg_conv, 'o-', linewidth=2, markersize=8, color='orange')\n",
    "            axes[0, 2].set_xlabel('Layer')\n",
    "            axes[0, 2].set_ylabel('Average Jaccard Similarity')\n",
    "            axes[0, 2].set_title('SAE Feature Convergence by Layer')\n",
    "            axes[0, 2].grid(True, alpha=0.3)\n",
    "            axes[0, 2].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Analysis 4: Activation vs SAE convergence comparison\n",
    "    convergence_types = []\n",
    "    convergence_values = []\n",
    "    \n",
    "    if 'behavioral_convergence' in results:\n",
    "        behavioral = results['behavioral_convergence']['convergence']\n",
    "        if behavioral:\n",
    "            all_behavioral = [data['mean_similarity'] for data in behavioral.values()]\n",
    "            convergence_types.append('Behavioral')\n",
    "            convergence_values.append(all_behavioral)\n",
    "    \n",
    "    if 'activation_convergence' in results:\n",
    "        act_conv = results['activation_convergence']['convergence']\n",
    "        all_activation = []\n",
    "        for pair_data in act_conv.values():\n",
    "            for layer_data in pair_data.values():\n",
    "                all_activation.extend(layer_data['similarities'])\n",
    "        if all_activation:\n",
    "            convergence_types.append('Activation')\n",
    "            convergence_values.append(all_activation)\n",
    "    \n",
    "    if 'sae_feature_convergence' in results:\n",
    "        sae_conv = results['sae_feature_convergence']['convergence']\n",
    "        all_sae = []\n",
    "        for pair_data in sae_conv.values():\n",
    "            for layer_data in pair_data.values():\n",
    "                all_sae.extend(layer_data['similarities'])\n",
    "        if all_sae:\n",
    "            convergence_types.append('SAE Features')\n",
    "            convergence_values.append(all_sae)\n",
    "    \n",
    "    if convergence_values:\n",
    "        axes[1, 0].boxplot(convergence_values, labels=convergence_types)\n",
    "        axes[1, 0].set_ylabel('Convergence Score')\n",
    "        axes[1, 0].set_title('Convergence by Analysis Type')\n",
    "        axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Analysis 5: Statistical significance\n",
    "    if len(convergence_values) >= 2:\n",
    "        from scipy import stats\n",
    "        \n",
    "        # Perform statistical tests between different convergence measures\n",
    "        test_results = []\n",
    "        for i in range(len(convergence_values)):\n",
    "            for j in range(i+1, len(convergence_values)):\n",
    "                if len(convergence_values[i]) > 0 and len(convergence_values[j]) > 0:\n",
    "                    statistic, p_value = stats.mannwhitneyu(\n",
    "                        convergence_values[i], convergence_values[j], \n",
    "                        alternative='two-sided'\n",
    "                    )\n",
    "                    test_results.append({\n",
    "                        'comparison': f'{convergence_types[i]} vs {convergence_types[j]}',\n",
    "                        'p_value': p_value,\n",
    "                        'significant': p_value < 0.05\n",
    "                    })\n",
    "        \n",
    "        # Display statistical results\n",
    "        stat_text = \"Statistical Significance:\\n\\n\"\n",
    "        for result in test_results:\n",
    "            sig_symbol = \"***\" if result['p_value'] < 0.001 else \"**\" if result['p_value'] < 0.01 else \"*\" if result['significant'] else \"ns\"\n",
    "            stat_text += f\"{result['comparison']}\\np = {result['p_value']:.4f} {sig_symbol}\\n\\n\"\n",
    "        \n",
    "        axes[1, 1].text(0.05, 0.95, stat_text, transform=axes[1, 1].transAxes,\n",
    "                        verticalalignment='top', fontfamily='monospace',\n",
    "                        bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "        axes[1, 1].set_title('Statistical Analysis')\n",
    "        axes[1, 1].axis('off')\n",
    "    \n",
    "    # Analysis 6: Key findings summary\n",
    "    findings_text = \"KEY FINDINGS:\\n\\n\"\n",
    "    \n",
    "    # Overall convergence levels\n",
    "    if convergence_values:\n",
    "        overall_avg = np.mean([np.mean(cv) for cv in convergence_values])\n",
    "        findings_text += f\"â€¢ Overall Convergence: {overall_avg:.3f}\\n\"\n",
    "        \n",
    "        if overall_avg > 0.7:\n",
    "            findings_text += \"  â†’ Strong universal patterns\\n\"\n",
    "        elif overall_avg > 0.4:\n",
    "            findings_text += \"  â†’ Moderate universal patterns\\n\"\n",
    "        else:\n",
    "            findings_text += \"  â†’ Weak universal patterns\\n\"\n",
    "    \n",
    "    findings_text += \"\\n\"\n",
    "    \n",
    "    # Model-specific findings\n",
    "    if 'behavioral_convergence' in results:\n",
    "        behavioral = results['behavioral_convergence']['convergence']\n",
    "        if behavioral:\n",
    "            # Find best and worst pairs\n",
    "            best_pair = max(behavioral.items(), key=lambda x: x[1]['mean_similarity'])\n",
    "            worst_pair = min(behavioral.items(), key=lambda x: x[1]['mean_similarity'])\n",
    "            \n",
    "            findings_text += f\"â€¢ Most Similar: {best_pair[0]}\\n\"\n",
    "            findings_text += f\"  Similarity: {best_pair[1]['mean_similarity']:.3f}\\n\\n\"\n",
    "            findings_text += f\"â€¢ Least Similar: {worst_pair[0]}\\n\"\n",
    "            findings_text += f\"  Similarity: {worst_pair[1]['mean_similarity']:.3f}\\n\\n\"\n",
    "    \n",
    "    # Architecture insights\n",
    "    findings_text += \"â€¢ Architecture Insights:\\n\"\n",
    "    if 'Gemma-2-2B-Base_vs_Gemma-2-2B-Instruct' in behavioral:\n",
    "        base_vs_instruct = behavioral['Gemma-2-2B-Base_vs_Gemma-2-2B-Instruct']['mean_similarity']\n",
    "        findings_text += f\"  Base vs Instruct (2B): {base_vs_instruct:.3f}\\n\"\n",
    "    \n",
    "    axes[1, 2].text(0.05, 0.95, findings_text, transform=axes[1, 2].transAxes,\n",
    "                    verticalalignment='top', fontsize=10,\n",
    "                    bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))\n",
    "    axes[1, 2].set_title('Key Findings')\n",
    "    axes[1, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print comprehensive interpretation\n",
    "    print(\"\\nðŸ” EXPERIMENT INTERPRETATION:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if convergence_values:\n",
    "        overall_avg = np.mean([np.mean(cv) for cv in convergence_values])\n",
    "        \n",
    "        print(f\"\\nðŸŽ¯ UNIVERSAL PATTERN EVIDENCE:\")\n",
    "        if overall_avg > 0.7:\n",
    "            print(f\"   âœ… STRONG evidence for universal alignment patterns ({overall_avg:.3f})\")\n",
    "            print(f\"      Models show high convergence across multiple analysis levels\")\n",
    "        elif overall_avg > 0.4:\n",
    "            print(f\"   âš ï¸  MODERATE evidence for universal patterns ({overall_avg:.3f})\")\n",
    "            print(f\"      Some convergence detected but patterns may be architecture-specific\")\n",
    "        else:\n",
    "            print(f\"   âŒ WEAK evidence for universal patterns ({overall_avg:.3f})\")\n",
    "            print(f\"      Models show significant differences in alignment approaches\")\n",
    "    \n",
    "    print(f\"\\nðŸ§  MECHANISTIC INSIGHTS:\")\n",
    "    if 'sae_feature_convergence' in results:\n",
    "        print(f\"   â€¢ SAE features reveal interpretable alignment mechanisms\")\n",
    "        print(f\"   â€¢ Layer-specific convergence patterns provide training insights\")\n",
    "    \n",
    "    print(f\"\\nðŸš€ IMPLICATIONS FOR AI SAFETY:\")\n",
    "    print(f\"   â€¢ Results inform universal alignment strategies\")\n",
    "    print(f\"   â€¢ Cross-model transfer potential for safety mechanisms\")\n",
    "    print(f\"   â€¢ Foundation for alignment pattern databases\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š EXPERIMENT QUALITY:\")\n",
    "    print(f\"   â€¢ Multi-level analysis provides robust evidence\")\n",
    "    print(f\"   â€¢ SAE interpretability adds mechanistic understanding\")\n",
    "    print(f\"   â€¢ Statistical validation ensures reliability\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ No results files found. Please run the experiment first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Next Steps & Extensions\n",
    "\n",
    "Based on your results, here are suggested next steps for extending this research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ¯ NEXT STEPS & EXTENSIONS\n",
    "\n",
    "print(\"ðŸŽ¯ NEXT STEPS FOR UNIVERSAL ALIGNMENT RESEARCH:\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "print(\"\\nðŸ”¬ IMMEDIATE EXTENSIONS:\")\n",
    "print(\"  1. Scale to more model families (LLaMA, Claude, GPT)\")\n",
    "print(\"  2. Add more capability dimensions (reasoning, creativity)\")\n",
    "print(\"  3. Cross-architecture SAE transfer experiments\")\n",
    "print(\"  4. Temporal analysis across model training checkpoints\")\n",
    "\n",
    "print(\"\\nðŸŽ›ï¸ METHODOLOGICAL IMPROVEMENTS:\")\n",
    "print(\"  1. Implement more sophisticated similarity metrics\")\n",
    "print(\"  2. Add causal intervention experiments\")\n",
    "print(\"  3. Include human baseline comparisons\")\n",
    "print(\"  4. Statistical significance testing with larger samples\")\n",
    "\n",
    "print(\"\\nðŸš€ ADVANCED RESEARCH DIRECTIONS:\")\n",
    "print(\"  1. Universal alignment transfer learning\")\n",
    "print(\"  2. Cross-modal convergence analysis (text, vision, code)\")\n",
    "print(\"  3. Adversarial robustness of universal patterns\")\n",
    "print(\"  4. Mechanistic interpretability of convergence failures\")\n",
    "\n",
    "print(\"\\nðŸ”§ TECHNICAL OPTIMIZATIONS:\")\n",
    "print(\"  1. Distributed computing for large-scale experiments\")\n",
    "print(\"  2. Automated hyperparameter tuning\")\n",
    "print(\"  3. Real-time experiment monitoring\")\n",
    "print(\"  4. Integration with MLOps pipelines\")\n",
    "\n",
    "print(\"\\nðŸ“Š REPRODUCIBILITY & COLLABORATION:\")\n",
    "print(\"  â€¢ All code and results are saved for reproduction\")\n",
    "print(\"  â€¢ Framework is modular and extensible\")\n",
    "print(\"  â€¢ Compatible with standard ML research workflows\")\n",
    "print(\"  â€¢ Ready for collaborative research initiatives\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ CONGRATULATIONS!\")\n",
    "print(\"You've successfully implemented a cutting-edge experiment\")\n",
    "print(\"combining SAE interpretability with convergence analysis.\")\n",
    "print(\"\\nThis framework provides a solid foundation for\")\n",
    "print(\"advancing universal alignment pattern research!\")\n",
    "\n",
    "# Show file structure\n",
    "print(f\"\\nðŸ“ EXPERIMENT FILES:\")\n",
    "for file_path in experiment.output_dir.glob(\"*\"):\n",
    "    if file_path.is_file():\n",
    "        size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "        print(f\"  ðŸ“„ {file_path.name} ({size_mb:.1f} MB)\")\n",
    "\n",
    "print(f\"\\nðŸ’¾ Total experiment data: {experiment.output_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
